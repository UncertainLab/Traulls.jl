%%% ArXiv template from https://www.overleaf.com/latex/templates/an-arxiv-template/gbzmznbxvwpr

\documentclass[10pt]{article}
\usepackage{graphicx}
\baselineskip=16pt

\usepackage{indentfirst,csquotes}

\topmargin= .5cm
\textheight= 20cm
\textwidth= 32cc
\baselineskip=16pt

\evensidemargin= .9cm
\oddsidemargin= .9cm

\usepackage{amssymb,amsthm,amsmath}
\usepackage{xcolor,paralist,hyperref,fancyhdr,etoolbox,cleveref}


\newtheorem{theorem}{Theorem}[]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{assumption}{Assumption}


\hypersetup{colorlinks=true, linkcolor=black, filecolor=black, urlcolor=black }
\def\proof{\noindent {\it Proof. $\, $}}
\def\endproof{\hfill $\Box$ \vskip 5 pt }









%%% PERSONAL ADD-ONS
\usepackage[square,sort,comma,numbers]{natbib}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tikz-cd}
\usepackage{enumitem}
\allowdisplaybreaks
\numberwithin{equation}{section}
%\usepackage{natbib}
\include{macros}

\newcommand{\inner}[2]{\left\langle {#1} , {#2} \right\rangle} % inner product
\newcommand{\proj}[2]{P_{#1} \left[ {#2} \right]} % Projection 
% For foot notes in author name
\newcommand{\footremember}[2]{%
	\footnote{#2}
	\newcounter{#1}
	\setcounter{#1}{\value{footnote}}%
}
\newcommand{\footrecall}[1]{%
	\footnotemark[\value{#1}]%
} 


% For foot notes / comments
\newif\ifnotes\notestrue

\def\boxnote#1#2{\ifnotes\fbox{\footnote{\ }}\ \footnotetext{ From #1: #2}\fi}
\def\fabian#1{\boxnote{Fabian}{\color{red}#1}}
\def\mfabian#1{{\color{red} #1}}
\def\hfabian#1{}

\def\pierre#1{\boxnote{Pierre}{\color{blue}#1}}
\def\mpierre#1{{\color{blue} #1}}
\def\hpierre#1{}

\def\todo#1{\boxnote{\textbf{TODO}}{#1}}
\def\mtodo#1{{#1}}
\def\htodo#1{}

\begin{document}
	
	\title{Trust Region Augmented Lagrangian for Constrained Nonlinear Least-Squares} %%%%%%%%%%%%
	\author{Pierre Borie\footremember{1}{University of Montreal, Department of Computer Science and Operations Research, Montreal, QC, Canada}}
	\date{}
	
	
	
	\maketitle
	
	
	\begin{abstract}
		\noindent In this paper, we present an algorithm for solving nonlinear least-squares problems subject to general and linear constraints. 
	\end{abstract} %%%%%%%%% 
	
	\tableofcontents
	
	\section{Introduction}
	We consider least squares problems subject to both nonlinear and linear constraints of the form
	\begin{equation}
		\label{eq:model_cnls}
		\begin{aligned}
			\min_{x\in \RR^n} \quad & \dfrac{1}{2} \|r(x)\|^2 \\
			\text{s.t.} \quad & c(x) = 0 \\
			& \inner{a_i}{x} = b_i,\quad i=1,\ldots,m \\
			& l \le x \le u,
		\end{aligned}
	\end{equation}
	where $r\colon \RR^n \to \RR^{n_r}$  and $c\colon \RR^n \to \RR^{n_c}$ are assumed to be nonlinear, potentially non convex, continuously differentiable functions, $\inner{\cdot}{\cdot}$ is the canonical inner product and $\|\cdot\| $ its induced euclidean norm, $a_i$ are $m$ vectors of $\Real^n$, $( m \le n)$, $b=(b_1,\ldots,b_m)^T \in \RR^m$ and $l$ and $u$ are vectors in $\RR^n$. Without loss of generality, some components of the latter two vectors can be set to $\pm \infty$ for unbounded parameters. In the context of least squares problems, components $r_i$ of the function $r$ are often denoted as the residuals.
	
	We state general assumptions on the problem.
	\begin{assumption}
		The residuals and constraints functions are twice continuously differentiable on $\Omega$ \label{assumption:functions_C2}.
	\end{assumption}
	\begin{assumption}\label{assumption:feasible_linear_cons}
		The feasible region for the linear constraints $\Omega$ is non-empty.
	\end{assumption}
	\begin{assumption}\label{assumption:full_rank_A}
		The vector $a_1,\ldots,a_m$ are linearly independent.
	\end{assumption}
	
	\subsection{Notations}
	Components of a vector $x\in\RR^n$ will be noted $x_i$ for $i=1,\ldots,n$. When describing iterative processes to solve problem~\eqref{eq:model_cnls}, we will index vectors and matrices by the iteration number. For instance, at iteration $k$, $(x_k,\lambda_k)$ is the current primal-dual iterate. For functions evaluated at $x_k$, we will note $r_k = r(x_k)$, $c_k :=c(x_k)$, $J_k:=J(x_k)$ and $C_k:=C(x_k)$. To not interfere with previous notation, we will add parentheses to relate to components of those quantities. For instance, $(x_k)_i$ will denote the $i$-th component of vector $x_k$.	
	
	We will often refer to the linear constraints of problem~\eqref{eq:model_cnls} as the convex set
	\begin{equation}\label{eq:linear_constraints}
		\Omega = \left\{ x \in \RR^n \ | \ Ax=b,\ l \le x \le u\right\},
	\end{equation}
	where $A$ is the matrix whose rows are the vectors $a_i$. By assumption~\ref{assumption:full_rank_A}, the matrix $A$ is full line rank. We note $\ker(A)$ its kernel, or null space. When relevant, we will refer specifically to the box constraints by $\calB$.
	Rewriting the objective function of problem~\eqref{eq:model_cnls} as $f\colon x \mapsto  \frac{1}{2} \|r(x)\|^2$, one has:
	\begin{subequations}
		\begin{align}
			\nabla f(x) &= J(x)^Tr(x)\label{subeq:ls_grad} \\
			\nabla^2 f(x) &= J(x)^TJ(x) +  \sum_{i=1}^{n_r} r_i(x) \nabla^2r_i(x) , \label{subeq:ls_hessian}
		\end{align}
	\end{subequations}
	where $J(x) = \left[\dfrac{\partial r_i}{\partial x_j}\right]_{(i,j)}$ is the jacobian matrix of the residuals.
	
	The Jacobian matrix of constraints function $c$ evaluated at $x$ is noted $C(x)$ and the Lagrangian function of problem~\eqref{eq:model_cnls}, with respect to the nonlinear constraints, is defined by 
	\begin{equation}
		\label{eq:lagrangian}
		\calL(x,\lambda) = f(x) + \inner{\lambda}{c(x)},
	\end{equation}
	where $\lambda \in \RR^{n_c}$ is the vector of Lagrange multipliers.
	
	We denote the orthogonal projection operator onto a closed and convex set $E \subset \RR^n$ by $\proj{E}{\cdot}$ with
	\begin{equation}\label{eq:projector}
		\proj{E}{x}= \argmin_{y\in E} \ \|x-y\|,\ \text{for}\ x \in E. 
	\end{equation}
	the argmin being a singleton when the set $E$ is closed and convex.
	
	When solving problem~\eqref{eq:model_cnls}, we search for a first-order critical point consisting of a primal-dual pair $(x^*,\lambda^*)$ satisfying the KKT conditions:
	\begin{equation}
		\begin{aligned}
			&x^* \in \Omega\ \text{and}\ c(x^*)=0 \\
			&\proj{\Omega}{x^*-\nabla_x \calL(x^*,\lambda^*)}=x^*
		\end{aligned}
	\end{equation}
	
	The rest of this paper is organized as follows. We present a general algorithm in section~\ref{sec:algo} and discuss algorithmic details in section~\ref{sec:inner_iteration}. Global convergence of our method is established in section~\ref{sec:global_convergence}.
	
	\section{Augmented Lagrangian Reformulation}\label{sec:algo}
	
	In this section, we introduce the framework of Augmented Lagrangian-based algorithms and describe an application in the least-squares setting of problem~\eqref{eq:model_cnls}.
	
	The Augmented Lagrangian function associated to the nonlinear constraints is defined by
	\begin{equation}\label{eq:al}
		\Phi_A(x,\lambda,\mu) := \dfrac{1}{2}\|r(x)\|^2 + \inner{\lambda}{c(x)} + \dfrac{\mu}{2} \|c(x)\|^2,
	\end{equation}
	where $\lambda\in \Real^m$ is the vector of Lagrange multipliers and $\mu > 0$ is the penalty parameter.
	
	We keep the linear constraints as is and only penalize the violation of the nonlinear constraints. 
	One has the following expression of the gradient: 
	\begin{equation}
		\label{eq:al_grad}
		\nabla_x \Phi_A(x,\lambda,\mu) = J(x)^Tr(x) + C(x)^T\bar{\lambda}(x,\lambda,\mu),
	\end{equation}
	with $\bar{\lambda}(x,\lambda,\mu):=\lambda + \mu c(x)$ generally referred as the first-order estimates of the Lagrange multipliers. 
	
	The Hessian is given by
	\begin{equation}\label{eq:al_hessian}
		\nabla^2_{xx} \Phi_A(x,\lambda,\mu) = J(x)^TJ(x) + \mu C(x)^TC(x) +  S(x) 
	\end{equation}
	with
	\begin{equation}\label{eq:al_hessian_2nd_terms}
		S(x) =\sum_{i=1}^{n_r} r_i(x) \nabla^2r_i(x) + \sum_{i=1}^{n_c} \nabla^2 c_i(x) \bar{\lambda}_i(x,\lambda,\mu)
	\end{equation}
	Function~\eqref{eq:al} is nothing than the Lagrangian~\eqref{eq:lagrangian} with a quadratic penalty term, hence the adjective \textit{Augmented}. For fixed $\lambda$ and $\mu$, reformulating problem~\eqref{eq:model_cnls} with function~\eqref{eq:al} gives the linearly constrained problem
	\begin{equation}\label{eq:cnls_al_reformulation} 
		\begin{aligned}
			\min_{x} \quad& \Phi_A(x,\lambda,\mu)  \\
			\text{s.t.}  \quad & x \in \Omega 
		\end{aligned}	
	\end{equation}
	Moving the nonlinear constraints into the objective simplifies the problem because only linear constraints are left, which enables one to use iterative methods for linearly constrained optimization while still improving feasibility of the nonlinear constraints. A local minimum of~\eqref{eq:cnls_al_reformulation} can be characterized the condition
	\begin{equation}\label{eq:al_sp_criticality_cond}
		x^* \in \argmin_{x \in \Omega} \Phi_A(x,\lambda,\mu) \iff \proj{\Omega}{x^*-\nabla_x \Phi_A(x^*,\lambda,\mu)} = x^*.
	\end{equation}
	where $\proj{\Omega}{\cdot}$ is the orthogonal projection onto $\Omega$, following the notation introduced in~\eqref{eq:projector}. 	
	Another pro of AL methods is that they come naturally with an update formula for the multipliers. Let \((x_k,\lambda_k)\) be the current primal-dual iterate, then we compute \(\lambda_{k+1} \) by
	\begin{equation}\label{eq:al_multipliers_update}
		\lambda_{k+1} = \bar{\lambda}(x_k,\lambda_k,\mu_k).
	\end{equation}
	%	This formula is often refered as the first-order multiplier update and is merely derived from \(\nabla_x\Phi_A=0\) by identifying the right hand side of equation~\eqref{eq:al_multipliers_update} as multipliers satisfying the KKT conditions \(\nabla_x \ell =0\).
	
	%	The idea behind AL methods is to find a solution of~\eqref{eq:cnls_al_reformulation} feasible for the nonlinear constraints. If the penalty parameter is high enough, there are guarantees that such a minimum is a first-order critical point of the original problem.
	%	Although the right hand-side of equivalence~\eqref{eq:al_sp_criticality_cond} can be used to assess first-order criticality, we will state our algorithm in terms of the more general notion of criticality measure. Formally, it is a non-negative function $\pi$ such that $\lim\limits_{k\to \infty} \pi(k,x_k)=0$ when $\left(x_k\right)_k$ is a sequence of iterates converging to a solution of our problem. For instance, the criticality measure corresponding to condition~\eqref{eq:al_sp_criticality_cond} is 
	%	\[\pi(k,x_k) = \left\Vert x_k - \proj{\Omega}{x_k-\nabla\Phi_A(x_k,\lambda_k,\mu_k)}\right\Vert.\]
	%	More details on criticality measures can be found in~\cite[][Chapter 7]{conn-etal:2000} and serve as the foundation of the convergence theory of projection methods with convex constraints.
	
	Our method is outlined in algorithm~\ref{algo:basic_al_trm} and is formulated for a general criticality measure $\pi$ that we have not specified yet. We shall see later in this paper that we will use measures different from~\eqref{eq:al_sp_criticality_cond} but that lead to equivalent consequences in terms of first-order criticality. In practice, our measure will only depend of the iterate and not the iteration index per se, so we will write $\pi(x_k)$ instead of $\pi(k,x_k)$.
	
	For references on general AL methods, we refer the reader to the implementation of the software for nonlinear programming named LANCELOT~\cite{conn-etal:1992} with contents based on~\cite{conn-etal:1988a,conn-etal:1991, conn-etal:1993, conn-etal:1996b} and summarized in~\cite[][Chapter 14]{conn-etal:2000}. See also~\cite{hestenes:1969,powell:1969,rockafellar:1973} for early theoretical considerations of the method of multipliers and~\cite{andreani-etal:2008,gillrobinson:2012,curtis-etal:2015, arreckx-etal:2016} for more recent implementations of AL algorithms. A basic implementation of an AL method is outlined in algorithm~\ref{algo:basic_al_trm} and we now discuss some of its general characteristics.
	\begin{algorithm}
		\caption{Augmented Lagrangian algorithm}\label{algo:basic_al_trm}
		\begin{algorithmic}[1]
			\Require Initial starting point $x^s_0 \in \Omega$, Lagrange multipliers estimate $\lambda_0$, penalty parameter $\mu_0$
			\State Penalty parameter increase factor $\tau > 1$, tolerance update constants $\omega,\eta, \kappa_\omega, \kappa_\eta, \beta_\omega, \beta_\eta$
			\State{Set initial tolerances $\omega_0\gets \omega \mu_0^{-\kappa_\omega}$ and $\eta_0\gets \eta \mu_0^{-\kappa_\eta}$}
			\For{K=0,1,2\ldots}
			\State\label{line:inner_iteration} Starting from $x_K^s$, approximately solve $\min_{x\in \Omega} \Phi_A(x,\lambda_K,\mu_K)$ to find $x_K \in \Omega$ such that \(\pi(x_K) \le \omega_K\)
			\If{$\|c(x_K)\| \le \eta_K$}
			\If{\(\pi(x_K) \le \omega_*\) and \(\left\Vert c(x_K)\right\Vert \le \eta_*\)}
			\State{\textbf{stop} and} \Return approximate solution $x_K$
			\EndIf
			\State Update the Lagrange multipliers $\lambda_{K+1}\gets \bar{\lambda}(x_K,\lambda_K,\mu_K)$ 
			\State Set the next starting point $x_{K+1}^s \gets x_K $
			\State Leave the penalty parameter unchanged \(\mu_{K+1} \gets \mu_K\)
			\State Decrease the tolerances $\omega_{K+1}\gets \omega_K \mu_{K+1}^{-\beta_\omega}$ and $\eta_{K+1}\gets \eta_K \mu_{K+1}^{-\beta_\eta}$
			\Else{}
			\State Let the iterate unchanged \(\left(x_{K+1}^s,\lambda_{K+1}\right) \gets \left(x_K^s,\lambda_K\right)\)
			\State Increase the penalty parameter $\mu_{K+1} \gets \tau\mu_K$
			\State Update tolerances $\omega_{K+1}\gets \omega \mu_{K+1}^{-\kappa_\omega}$ and $\eta_{K+1}\gets \eta \mu_{K+1}^{-\kappa_\eta}$
			\EndIf
			\EndFor
		\end{algorithmic}
	\end{algorithm}
	One first notices that algorithm~\ref{algo:basic_al_trm} has a outer-inner iteration structure, in the sense that each iteration $K$ requires to approximately solve an optimization problem (line~\ref{line:inner_iteration}), which also involves an iterative process. To highlight the distinction between the two, we use the subscript $K$ for the outer iterates, i.e. the main iterates, and $k$ for the iterates relative to the inner minimization. The techniques used for the latter are detailed in section~\ref{sec:inner_iteration}.
	
	Tolerances in algorithm~\ref{algo:basic_al_trm} are updated in such a way that both sequences $\omega_K$ and $\eta_K$ tend to $0$ when $K \to \infty$. The update scheme that we outline follows the rules described in~\cite[][Chapter 14]{conn-etal:2000}. The paramaters values used in our impletation are given in section~\ref{sec:implementation_details}

	As a criticality measure, we use the norm of the reduced gradient and thus set
	\begin{equation}\label{eq:crit_measure:reduced_gradient_norm}
		\pi(x_K) = \left\Vert \tilde{N}(x_K)^T \nabla_x \Phi_A(x_K,\lambda_K,\mu_K) \right\Vert,
	\end{equation}
	where  $\tilde{N}(x_K)$ is an orthonormal matrix whose columns span the null space of the constraints active at $x_K$, i.e. all the linear equalities and active bounds. As shown in~\cite{conn-etal:1996b}, this criticality measure can be used to prove global convergence of AL methods following the procedure outlined in algorithm~\ref{algo:basic_al_trm}. 	 
	
	\section{About the inner minimization process}\label{sec:inner_iteration}
	
	In this section, we also use the iteration subscript $k$ but we keep in mind that they are distinct from the outer iterates of algorithm~\ref{algo:basic_al_trm}.
	Given a point $x^s \in \Omega$, multipliers estimates $\lambda$, a penalty parameter $\mu$, we aim to find an approximate solution of the problem
	\begin{equation}\label{eq:inner_itr_subpb}
		\begin{aligned}
			\min_x \quad & \Phi_A(x,\lambda,\mu) \\
			\text{s.t.} \quad & x \in \Omega,
		\end{aligned}
	\end{equation}
	starting from $x_0=\in \Omega$ and such that
	\begin{equation}\label{eq:approximate_firstorder_critical_al}
		\pi(x)\le \omega,
	\end{equation}
	for the criticality measure $\pi$ defined at~\eqref{eq:crit_measure:reduced_gradient_norm} and tolerance $\omega > 0$. This task also involves an iterative process, for which the iterates will be indexed with subscript $k$, as a distinction from the outer iterates of algorithm~\ref{algo:basic_al_trm}. At each iteration $k$, we compute a step $s_k$ and recursively update the iterate by $x_{k+1}=x_k+s_k$. The step is obtained after minimizing a model of the objective function $\varphi : x\mapsto \Phi_A(x,\lambda,\mu)$ around $x_k$. We consider the quadratic model:
	\begin{equation}\label{eq:al_quadratic _model}
		m_k(x) = \varphi_k + \inner{g_k}{x-x_k} + \dfrac{1}{2}\inner{x-x_k}{H_k(x-x_k)},
	\end{equation}
	where $\varphi_k:=\varphi(x_k)$, $g_k:=\nabla_x \varphi(x_k)$ and $H_k$ is a symmetric approximation of the true Hessian $\nabla^2_{xx} \varphi(x_k)$. Using the latter would impact negatively the performance of the algorithm because computing the second order terms~\eqref{eq:al_hessian_2nd_terms} requires too much time and storage in practice. We discuss the aspects of the methods relative to the choice of approximation in subsection~\ref{subsec:hessian_approx}. 
	Model~\eqref{eq:al_quadratic _model} is appropriate to describe the algorithm in terms of the iterate. When discussing about subproblems, we prefer to emphasis on the step and would then use the following model of the primal reduction $\varphi(x_k+s)-\varphi(x_k)$, given by
	\begin{equation}\label{eq:al_quadratic_reduction_model}
		q_k(s) = \dfrac{1}{2}\inner{s}{H_ks} + \inner{g_k}{s}.
	\end{equation}
	
	One has $q_k(x-x_k)=m_k(x)-m_k(x_k)$.
	
	We seek to compute the step $s_k$ as an approximate solution of the program
	\begin{subequations}
		\begin{align}
			\min_{s} \quad& q_k(s)  \\
			\text{s.t.}  \quad & x_k+s \in \Omega \\ 
			& \|s\|_\infty \le \Delta_k, \label{subeq:inf_norm_tr_constraint}
		\end{align}	
	\end{subequations}
	Vector $s$ denotes the unknown of the subproblem whose solution $s_k$ is the step and is used to compute the new iterate $x_{k+1}=x_k+s_k$.
	
	The constraints $x_k+s\in \Omega$ are satisfied as long as the steps satisfy:
	\begin{itemize}
		\item \(As=0\) (provided that $Ax_0=b$)
		\item$ x_k-l \le s \le u-x_k$
	\end{itemize}
	
	Since the infinite-norm trust region constraint is equivalent to imposing $x_i \in [-\Delta_k,\Delta_k]$ for all $i$, we can rewrite this subproblem	
	\begin{subequations}\label{eq:qsubpb} 
		\begin{align}
			\min_{s} \quad& q_k(s)  \\
			\text{s.t.}  \quad & As=0 \\
			& l_k \le s \le u_k, \label{subeq:qsubpb_bounds}
		\end{align}	
	\end{subequations}
	with $(l_k)_i = \max\left(-\Delta_k,l_i-(x_k)_i\right)$ and $(u_k)_i = \min\left(\Delta_k,u_i-(x_k)_i\right)$ for all $i=1,\ldots,n$.
	
	In our method, we incorporate a trust-region strategy to control and assert the quality of a step. Therefore, we add to each subproblem the constraint $\|s\|_\infty \le \Delta_k$ with a radius $\Delta_k > 0$. This constraint reflects the domain on which we believe that the model well approximates the true function. The success of an iteration and update the trust region is evaluated by the ratio
	\begin{equation}\label{eq:tr_ratio}
		\rho_k = \dfrac{\varphi(x_k+s_k)-\varphi(x_{k})}{q_k(s_k)}.
	\end{equation}
	We follow the standard step acceptance criteria~\cite{conn-etal:2000}, which require constants $\eta_1, \eta_2, \gamma_1, \gamma_2$ such that 
	\begin{equation}\label{eq:cond_constants_step_acceptance}
		0< \eta_1 \le \eta_2 < 1 \text{ and } 0< \gamma_1 \le \gamma_2 < 1.
	\end{equation}
	If $\rho_k  > \eta_1$, the step is accepted and the trust region is expanded. Otherwise, the step is rejected and the region reduced. A typical scheme to update the radius $\Delta_k$ would be to set
	\begin{equation}\label{eq:tr_basic_update}
		\Delta_{k+1} \in \left\{\begin{aligned}
			& \left[\Delta_k,\infty\right) & &\text{if } \rho_k \ge \eta_2 \\
			& \left[\gamma_2\Delta_k, \Delta_k\right]  & &\text{if } \rho_k \in [\eta_1,\eta_2) \\
			& \left[\gamma_1\Delta_k, \gamma_2\Delta_k\right]  & &\text{if }  \rho_k<\eta_1
		\end{aligned}\right.
	\end{equation}
	The procedure employed to solve subproblem~\eqref{eq:qsubpb} is described in algorithm~\ref{algo:trinner_iteration} and the latter is analyzed in the rest of this section. 
	\begin{algorithm}
		\caption{Trust region inner iteration algorithm}
		\label{algo:trinner_iteration}
		\begin{algorithmic}[1]
			\Require initial point $x_0 \in \Omega$, radius $\Delta_0 >0$, constants $\eta_1, \eta_2, \gamma_1, \gamma_2, \gamma_3$ satisfying conditions~\eqref{eq:cond_constants_step_acceptance}.
			\State set $k \gets 0$ 
			\Repeat{}
			\State compute the model $m_k$
			\State compute a step $s_k$ that sufficiently reduces the model
			\State compute the ratio $\rho_k$~\eqref{eq:tr_ratio}
			\If{$\rho_k > \eta_1$} set $x_{k+1}\gets x_k+s_k$ \Else{} set $x_{k+1} \gets x_k$ \EndIf
			\State set $\Delta_{k+1}$ according to~\eqref{eq:tr_basic_update}
			\State increment $k\gets k+1$
			\Until{$\pi(x_k) \le \omega$}
		\end{algorithmic}
	\end{algorithm}
	We consider the current feasible iterate $x_k$ and its associate approximate quadratic model $q_k$ as defined in~\eqref{eq:al_quadratic_reduction_model}.
	
	
	
	We propose to solve this problem using the projected gradient method. This consists into first performing a gradient projection step and then applying the conjugate gradient (CG) method until a bound is reached and restart with a new active set until a termination criteria is satisfied.
	For a vector $x$, we will denote by $\calA(x)$ the set of bounds constraints active at $x$, which sets the corresponding components of the step to $0$. The indices of the remaining variables, or free variables, will be noted $\calF(x_k)$.
	
	The convergence analysis of our this procedure relies on the generalized Cauchy point in the sense of~\cite[][Chapter 12]{conn-etal:2000}, i.e. a minimizer of the quadratic model along the projected steepest direction. Formally, we first define the Cauchy step $s^C_k$ as $s_k(t_k)$, where 
	\begin{equation}\label{eq:projected_gradient_path}
		s_k(t)=\proj{\Omega}{x_k-tg_k}-x_k \text{ for } t\ge 0.
	\end{equation}
	The scalar $t_k$ is chosen such that the Cauchy point $x_k^C:= x_k+s^C_k$ performs a sufficient reduction of the objective model. Following projected gradient theory~\cite{burke-etal:1990,linmore:1999a} we require that
	\begin{equation}\label{eq:cauchy_sufficient_decrease}
		\begin{aligned}
			q(s_k^C) \le \kappa_1 \inner{g_k}{s_k^C}, \quad  \left\Vert s_k^C\right\Vert_\infty \le \Delta_k,
		\end{aligned}
	\end{equation}
	with constants $\kappa_1 \in \left(0,\frac{1}{2}\right)$. In the literature, the second condition is often stated with the Euclidean norm as $\left\Vert s_k^C\right\Vert \le \kappa \Delta_k$ for a constant $\kappa \in (0,1]$. In most implementations, this constant is set to $1$ so it reduces to requiring that the step lies within the trust region. In our framework, feasibility of the step relative to the trust region is handled implicitly by iteration-dependent bounds~\eqref{subeq:qsubpb_bounds}.
	
	\subsection{Cauchy point computation}
	To compute the Cauchy point, we need to find a positive scalar $t_k$ such that the step $s_k(t_k)$ satisfies~\eqref{eq:cauchy_sufficient_decrease}. 
	%	To do so, we form a decreasing or increasing sequence $t_k^{(0)}, t_k^{(1)},\ldots$ in an Armijo mechanism. If the step $s(t_k^{(0)})$ does not satisfy~\eqref{eq:cauchy_sufficient_decrease}, we reduce the trial value by a constant factor until~\eqref{eq:cauchy_sufficient_decrease} is satisfied.
	%	If, on the contrary, $s(t_k^{(0)})$ satisfies~\eqref{eq:cauchy_sufficient_decrease}, we increase the trial values by a constant factor until~\eqref{eq:cauchy_sufficient_decrease} fails and set $t_k$ to the last successful trial value. In other words, if $s(t_k^{(0)})$ satisfies~\eqref{eq:cauchy_sufficient_decrease}, then we set
	%	\[t_k = \gamma_c^{m_k} t_k^{(0)},\]
	%	where $\gamma_c \in \left(1,\infty\right)$ and $m_k$ is the first integer such that~\eqref{eq:cauchy_sufficient_decrease} fails at $\gamma^{m_k+1} t_k^{(0)}$.
	%	On the contrary, if~\eqref{eq:cauchy_sufficient_decrease} fails at $t_k^{(0)}$, we set
	%	\[t_k = \gamma_c^{-m_k} t_k^{(0)},\]
	%	where $\gamma_c \in \left(1,\infty\right)$ and $m_k$ is the first integer such that~\eqref{eq:cauchy_sufficient_decrease} is satisfied at $\gamma^{m_k} t_k^{(0)}$. Setting $\gamma_c=10$ works well in practice~\cite{conn-etal:1992,moretoraldo:1991}. For the initial trial value, following~\cite{linmore:1999a}, we first set $t_k^{(0)}=1$ when $k=0$ and then set $t_k^{(0)}=t_{k-1}$ for the next iterations.
	
	For the total step $s_k$, we require that it lies within the trust region and results in a feasible point that achieves at least a fraction of the decrease obtained by the Cauchy point, i.e.
	\begin{equation}\label{eq:step_sufficient_decrease}
		\begin{aligned}
			q(s_k) \le \kappa_1 q_k\left(s_k^C\right), \quad \|s_k\|_\infty \le  \Delta_k, \quad x_k+s_k\in \Omega.
		\end{aligned}
	\end{equation}
	By ensuring that our algorithm performs such a decrease, one can prove global convergence to a critical point of~\eqref{eq:inner_itr_subpb}. Framing this into the conduct of algorithm~\ref{algo:basic_al_trm}, this guarantees that we will find a point satisfying the approximate first-order criticality condition~\eqref{eq:approximate_firstorder_critical_al}. Nevertheless, this procedure requires to compute the projection of the gradient direction~\eqref{eq:projected_gradient_path} on the feasible set $\Omega$ at every new trial value of the scalar $t$. When $\Omega$ only contains bound constraints, the projection is trivial and cheap to compute. The linear equalities case is more costly but can still be handled efficiently by a \textit{normal equations} or \textit{augmented system} approach~\cite{gould-etal:2001}. When $\Omega$ is of the form~\eqref{eq:linear_constraints}, the projection is not direct and requires to solve the associated quadratic program $\min_{v \in \Omega} \ \|v +tg_k-x_k \|$. In our current implementation, we solve the latter with an interior point method for QP~\cite{mehrotra:1992}. For now, we use this approach for its global convergence guarantees, but we are working on a procedure that finds the first local minima on the projected gradient path~\eqref{eq:projected_gradient_path}, as in~\cite{conn-etal:1988a}, but adapted to our case.
	
	We now describe a procedure to compute the Cauchy point as the first local minimizer of the quadratic model along the projected gradient path. We have adapted the method described in~\cite{conn-etal:1988a} to the case where linear equalities are present. For the seek of clarity, we omit the iteration index during the rest of this subsection.
	The piece-wise arc $s(t)$ at \eqref{eq:projected_gradient_path} has breakpoints:
	\begin{equation}\label{eq:projected_gradient_breakpoints}
		0=t_0 < t_1 < \ldots < t_{n-m} < t_{n-m+1} = \infty,
	\end{equation} 
	that correspond to the successive scalars at which the projected direction is bend.
	Note that since $A$ has $m$ rows and is full rank, there are $n-m$ degrees of freedom remaining  and thus at most $n-m$ breakpoints before the projected gradient path is constant. We define $t_0$ and $t_{n-m+1}$ for notation commodity. 
	Contrary to the case with bound constraints, we can not merely set the component of the projected gradient hitting a breakpoint to $0$ but actually need to compute another projection of the negative gradient on a new subspace where the component corresponding to a breakpoint is fixed to $0$. Initially, $\calA(x) = \left\{ j\ | \ x_j \in \{l_j,u_j\}\right\}$ so the first direction $d^{(0)}$ is the projection of $-g$ onto 
	\[\null(A) \cap \left\{v\ | \ v_j =0,\ j\in\calA(x)\right\}.\]
	Next, if $i_1,\ldots,i_p$ are the indices of the variables fixed after hitting the $i^{th}$ breakpoint, let $N_i$ be a full column rank matrix that spans the subspace
	\[\ker(A) \cap \left\{v\ | \ v_j =0,\ j=i_1,\ldots,i_p\right\}.\]
	The corresponding search direction $d^{(i)}$ is the projection of $-g$ onto this subspace, given explicitly by
	\begin{equation}\label{eq:subspace_proj_gradient}
		d^{(i)} = -N_i\left(N_i^TN_i\right)^{-1}N_i^Tg.
	\end{equation}
	We respectively denote by $d^{(l)}$ and $d^{(u)}$ the lower and upper bounds of the form~\eqref{subeq:qsubpb_bounds} on the directions $d^{(i)}$.
	To find the first local minimum of the scalar function $\varphi$, we successively study each interval $[t_i,t_{i+1})$ to assert whether or not it contains a local minimizer. One can show that the expression of the step alongside the projected gradient arc is
	\begin{equation}
		s(t) = \proj{\Omega}{x-tg} - x = s^{(i)} + \Delta t d^{(i)} \text{ for } t \in [t_i,t_{i+1}),
	\end{equation}
	where $d^{(i)}$ is given by~\eqref{eq:subspace_proj_gradient}, $\Delta t = t-t_i$ and
	\[s^{(i)} = \sum_{k=1}^{i-1} (t_k-t_{k-1})d^{(k-1)}.\]
	Assume we have not found a local minimizer on $[t_0,t_i)$ and thus look at the interval $[t_i,t_{i+1})$. The model along this arc can be written
	\begin{equation}\label{eq:model_projected_gradient_interval}
		q(s(t)) = \dfrac{\phi_i''}{2}(\Delta t)^2 + \phi_i'\Delta t  + \phi_i,
	\end{equation}
	with
	\begin{itemize}
		\item $\phi_i'' = \inner{d^{(i)}}{Hd^{(i)}}$
		\item $\phi_i' =\inner{s^{(i)}}{Hd^{(i)}} + \inner{g}{d^{(i)}}$
		\item $\phi_i = q(s^{(i)})$
	\end{itemize}
	Different cases can occur depending on the values of the slope $\phi_i'$ and the curvature $\phi_i''$. 
	Firstly, if
	\begin{align*}
		&\phi_i' > 0 \text{ or } \\
		&\phi'_i=0 \text{ and } \phi_i'' > 0,
	\end{align*}
	then $t_i$ is the required minimizer. Next, if
	\[\phi_i' < 0 \text{ and } \phi_i'' > 0,\]
	the quadratic~\eqref{eq:model_projected_gradient_interval} has a strict minimizer at
	\[t_i- \dfrac{\phi_i'}{\phi_i''}.\]
	If the latter belongs to the interval of interest, i.e. 
	\[t_i-\phi_i'/\phi_i'' < t_{i+1},\]
	then it is the required minimizer. In other cases, the minimizer is at or beyond $t_{i+1}$. To prepare for the study of the next interval, we first need to find the next breakpoint, given by the smallest scalar $t_{i+1}>t_i$ such that, at $s(t_{i+1})$, one of the free component hits one of its bounds. By introducing
	\[\delta_i^- = \max_{d^{(i)}_j < 0 }\left\{ d^{(l)}_j/d^{(i)}_j\right\}, \qquad \delta_i^+ =  \min_{d^{(i)}_j > 0 } \left\{d^{(u)}_j/d^{(i)}_j\right\},\]
	the next breakpoint is given by 
	\begin{equation}\label{eq:next_breakpoint}
		t_{i+1} = t_i + \delta_i,
	\end{equation} 
	with $\delta_i = \min\left(\delta_i^-,\delta_i^+\right)$. We then add the corresponding variable index to the list of fixed components, compute the projection $d^{(i+1)}$ by~\eqref{eq:subspace_proj_gradient} and finally update the slope and curvature of the model along the next interval. A last termination case can occur. Since $A$ is of rank $m$, at most $n-m$ bounds can become active so if we never find a local minimum, the procedure still ends whenever it reaches the breakpoint $t_{n-m}$. Indeed, past this breakpoint, the model along the projected gradient path is constant so we can return the last accumulated step $s^{(n-m)}$ as the Cauchy step. Note that, in this case, it is also the total step, because no more variables can me modified.
	The procedure for the Cauchy step computation is outlined in algorithm~\ref{algo:cauchy_point}.
	\begin{algorithm}
		\caption{Cauchy step computation}\label{algo:cauchy_point}
		\begin{algorithmic}[1]
			\Require Hessian $H$, gradient $g$ bounds on the direction $d^{(l)},\ d^{(u)}$
			\State Identify $\calA(x)$ and compute the direction $d^{(0)}$
			\State Set \textbf{found} $\gets$ \textbf{false} 
			\State Set $t_0\gets 0$, $s^{(0)}\gets 0$ and initialize counter $i\gets 0$
			\Repeat
			\State $\phi_i' \gets \inner{g}{d^{(i)}},\ \phi_i'' \gets \inner{d^{(i)}}{Hd^{(i)}}$
			\State Find the next breakpoint $t_{i+1}$ by~\eqref{eq:next_breakpoint}
			\If{$\phi_i' > 0 \text{ or } \phi'_i=0 \text{ and } \phi_i'' > 0$}
			\State $s^C \gets s^{(i)}$
			\State \textbf{found $\gets$ \textbf{true}}
			\ElsIf{$\phi_i' < 0 \text{ and } \phi_i'' > 0$ \text{ and } $t_i- \phi_i'/\phi_i'' < t_{i+1}$}
			\State $\Delta t \gets - \phi_i'/\phi_i''$
			\State $s^C \gets s^{(i)} + \Delta t d^{(i)}$, \textbf{found $\gets$ \textbf{true}}
			\Else
			\State $\Delta t \gets t_{i+1}-t_i$
			\State Compute the next direction $d^{(i+1)}$ by~\eqref{eq:subspace_proj_gradient}
			\State $s^{(i+1)} \gets s^{(i)} + \Delta t d^{(i)}$
			\EndIf
			\State Increment $i \gets i+1$
			\If{$i=n-m-|\calA(x)|$}
			\State $s^C \gets s^{(i)}$, \textbf{found} $\gets$ \textbf{true}
			\EndIf
			\Until{\textbf{found}}
			\State \Return $s^C$
		\end{algorithmic}
	\end{algorithm}
	
	\subsection{Projected conjugate gradient}
	
	We come back to the conduct of the inner iteration and assume we have found a Cauchy step $s_k^C$ that satisfies~\eqref{eq:cauchy_sufficient_decrease}. In order to have an efficient algorithm, we want the total step to achieve a better reduction than the Cauchy step. To do so, we build the next iterate $x_{k+1}$ after a finite sequence of $M$ minor iterates $x_{k,1},\ldots,x_{k,M+1}$. The sequence starts at the Cauchy point and ends at the next iterate, i.e. $x_{k}+s_k^C=x_{k,1}$ and $x_{k+1}=x_{k,M+1}$. This type of approach has shown to be effective for general optimization with bound constraints~\cite{linmore:1999a} and has also been incorporated into other AL algorithms for the inner loop minimization~\cite{conn-etal:1992,arreckx-etal:2016}.
	
	Each minor iterate is defined after the previous one and is decomposed into 
	\[x_{k,j+1}=x_{k,j}+\alpha_{k,j}w_{k,j},\]
	where $w_{k,j}$ is a descent direction for the quadratic model $q_k$ and $\alpha_{k,j}$ is a steplength. For each minor iterate, we require
	\begin{equation}\label{eq:minor_iterate_feasible}
		\begin{aligned}
			x_{k,j} \in \Omega, & & \|x_{k,j} - x_k \|_\infty \le \Delta_k, & & \calA(x_k^C) \subseteq \calA(x_{k,j}).
		\end{aligned}
	\end{equation}
	The first two conditions are merely that each minor iterate is feasible and the associated step lies within the trust region, while the last condition means that we can only add active bounds during this process.
	We also require the sufficient decrease between two successive minor iterates
	\begin{equation}\label{eq:minor_iterate_decrease}
		m_k(x_{k,j+1}) \le m_k(x_{k,j}), \qquad j = 1,\ldots,M.
	\end{equation}
	After each minor iteration, the corresponding step is $s_{k,j}:=x_{k,j}-x_k$.
	
	The search direction $w_{k,j}$ is an approximate minimizer of the subproblem
	\begin{subequations}\label{eq:minor_subpb}
		\begin{align}
			\min_w \quad & m_k(x_{k,j}+w) \\
			\text{s.t.} \quad & Aw=0 \label{subeq:minor_subpb_eq_cons} \\
			& w_i = 0, \qquad i \in \calA(x_{k,j}) \label{subeq:minor_subpb_fix_bounds}.
		\end{align}
	\end{subequations}
	The free variables are implicitly subject to the bounds 
	\begin{equation}\label{subeq:minor_subpb_bounds}
		\left(l_{(k,j)}\right)_i \le w_i \le \left(u_{(k,j)}\right)_i, \qquad i \in \calF(x_{k,j})
	\end{equation}
	where $l^{(k,j)}:= l_k - s_{k,j}$ and $u^{(k,j)}:= u_k - s_{k,j}$. We denote by $\calB^{(k,j)}$ the box defined by constraints~\eqref{subeq:minor_subpb_bounds}.
	The steplength $\alpha_{k,j}$ is computed by a one dimensional minimization of $m_k(x_{k,j}+\alpha w_{k,j})$ on the intersection of the line $\alpha \ge 0$ with the feasible domain.
	
	%	by a projected search along direction $w_{k,j}$, i.e. such that the point $\proj{\Omega}{x_{k,j}+\alpha_kw_{k,j}}$ provides a sufficient reduction.
	%	After computing all the minor iterates, the step is defined as $s_k = x_{k,p+1}-x_k$.
	
	We now describe how the minor subproblem~\eqref{eq:minor_subpb} is solved. The idea is to apply the projected conjugate gradient~\cite{gould-etal:2001} method with the previous minor iterate $x_{k,j}$ as a starting point. Three termination cases can occur. First, we can generate a direction such that a component in the current active set $\calA(x_{k,j})$ violates one on the bounds~\eqref{subeq:minor_subpb_bounds}. When this happens, we scale the direction so that the associate component lies at the bound and stop the CG iterations. The second case occurs when we generate a direction of negative curvature and is handled similarly as the firs one, i.e. we modify the direction so that it reaches the limit of the feasible set. The third case is the normal termination one and occurs when we find a local minimizer, with respect to a given tolerance. In all cases, we return the obtained search direction $w_{k,j}$, perform the projected line search to compute the point $x_{k,j+1}$ such that~\cref{eq:minor_iterate_feasible,eq:minor_iterate_decrease} are verified. The handling of the termination cases differ in the continuation of the procedure. The last two cases (negative curvature and local minimality), cause the stopping of our minor iterates mechanism. On the contrary, if the CG iterations stopped because a bound was hit, we go back to solving~\eqref{eq:minor_subpb} using projected conjugate gradient method with $x_{k,j+1}$ as a starting point and $\calA(x_{k,j+1}) \supset \calA(x_{k,j})$ as a new set of fixed components.
	
	Each iteration of the conjugate gradient method applied to~\eqref{eq:minor_subpb} requires computing projections onto the null space of the constraints~\eqref{subeq:minor_subpb_fix_bounds}--\eqref{subeq:minor_subpb_fix_bounds}. We denote the associated projection operator, in this case a $n\times n$ matrix, by $\tilde{P}$. The specification of the projected conjugate gradient method applied to solving~\eqref{eq:minor_subpb} is outlined in algorithm~\ref{algo:projected_cg_method}.
	
	\begin{algorithm}
		\caption{The projected conjugate gradient method applied to~\eqref{eq:minor_subpb}}\label{algo:projected_cg_method}
		\begin{algorithmic}[1]
			\Require Positive constant $\kappa_{2}=0.1$
			\State\label{line:pcg_initial_projection}Set $w \gets 0,\ r \gets H_k(x_{k,j}-x_k)+g_k,\ v\gets \tilde{P}r,\ p \gets -v$
			\State Set tolerance $\varepsilon_{cg} \gets \kappa_{2}\|v\|$
			\Repeat
			\If{$\inner{p}{H_kp}\le 0$}
			\State $w^+ \gets w + \gamma p$ where $\gamma$ is the smallest factor such that $w^+_i \in \{l^{(k,j)}_i,u^{(k,j)}_i\}$ 
			\State for $i \in \calF(x_{k,j})$
			\State \textbf{STOP}
			\EndIf
			\State $\alpha \gets \inner{r}{v} / \inner{p}{H_kp}$
			\State $w^+ \gets w+\alpha p$
			\If{$w^+ \notin \calB^{(k,j)}$}
			\State $w^+ \gets w + \gamma p$ where $\gamma$ is the smallest factor such that $w^+_i \in \{l^{(k,j)}_i,u^{(k,j)}_i\}$
			\State for $i \in \calF(x_{k,j})$
			\State \textbf{STOP}
			\EndIf
			\State $r^+ \gets r + \alpha H_kp$
			\State\label{line:pcg_iteration_projection}$v^+\gets \tilde{P}r^+$
			\If{$\sqrt{\inner{r^+}{v^+}} < \varepsilon_{cg}$} \textbf{STOP}
			\EndIf
			\State$\beta \gets \inner{r^+}{v^+} / \inner{r}{v}$ 
			\State $p \gets -v^+ + \beta p$
			\State $w\gets w^+,\ r \gets r^+,\ v \gets v^+$
			\Until{$2(n-m-|\calA(x_{k,j})|)$ iterations have been done} 
			\State{}
			\Return $w^+$
		\end{algorithmic}
	\end{algorithm} 
	We now detail how the projections occurring at lines~\ref{line:pcg_initial_projection}~and~\ref{line:pcg_iteration_projection} are computed. Writing the set of active bounds as $\calA(x_{k,j}) =  \left\{i_1,\ldots, i_p\right\}$, $p < n-m$, we denote by $Z \in \RR^{p\times n}$ the matrix whose row $k$ is the row $i_k$ of the $n\times n$ identity matrix. Then, constraints~\eqref{subeq:minor_subpb_fix_bounds}--\eqref{subeq:minor_subpb_fix_bounds} are equivalent to the set of linear equations
	\begin{equation}\label{eq:active_constraints_matrix}
		\tilde{A}w=0,\qquad \tilde{A} = \begin{pmatrix}
			A \\Z
		\end{pmatrix} \in \RR^{(m+p)\times n}.
	\end{equation} 
	Let $\tilde{N}$ be a matrix whose columns form an orthonormal basis of the null space of $\tilde{A}$. By construction and our full rank assumption~\ref{assumption:full_rank_A}, $\tilde{A}$ is also full rank. Then, for the projection of a vector $v$ onto the null space of $\tilde{A}$ is given by $\tilde{P}v$ where
	\[\tilde{P} = \tilde{N}\left(\tilde{N}^T\tilde{N}\right)^{-1}\tilde{N}^T,\]
	There is no need to explicitly form the matrix $\tilde{N}$ because we can make use of the equivalent expression of the projection matrix $\tilde{P}$:
	\begin{equation}\label{eq:minor_subpb_projector}
		\tilde{P} = I - \tilde{A}^T\left(\tilde{A}\tilde{A}^T\right)^{-1}\tilde{A}.
	\end{equation}
	Using~\eqref{eq:minor_subpb_projector}, one can compute $r^+ = \tilde{P}v^+$ in algorithm~\ref{algo:projected_cg_method} by first solving, for an auxiliary variable $y$, the linear system
	\begin{equation}\label{eq:proj_normal_eq_auxiliary_syst}
		\left(\tilde{A}\tilde{A}^T\right)y = \tilde{A}v^+,
	\end{equation}
	and retrieve the projection by
	\begin{equation}
		r^+ = v^+ - \tilde{A}^T y.
	\end{equation}
	This approach, referred as the \textit{normal equations} approach~\cite{gould-etal:2001}, requires to solve the system~\eqref{eq:proj_normal_eq_auxiliary_syst}. This is done by using the Cholesky decomposition of $\tilde{A}\tilde{A}^T$. The latter is well defined because being well defined the matrix $\tilde{A}\tilde{A}^T$ is symmetric by construction and positive definite by assumption~\ref{assumption:full_rank_A}. System~\eqref{eq:proj_normal_eq_auxiliary_syst} is reduced to two successive lower triangular systems. The factorization $\tilde{A}\tilde{A}^T = \tilde{L}\tilde{L}^T$, with $\tilde{L}$ lower triangular, does not need to be computed from scratch because the structure of $\tilde{A}$ implies a block structured Cholesky factor that involves the Cholesky decomposition of $AA^T$. The latter is constant throughout the algorithm, so the factor $\tilde{L}$ can be computed in a relatively efficient manner, even though it potentially has to be updated at every new minor iteration. We expect it to be the case when these computations take place in the first outer iterations of algorithm~\ref{algo:basic_al_trm}, but that as we progress toward a first-order critical point, the set of active bounds tends to stabilize and remain the same during the inner iterations. Details on this computation can be found in the appendix~\ref{appendix:chol_aug_matrix}. We also refer the reader to~\cite{golubvanloan:2013} for the computation the Cholesky decomposition of matrices with a block structure.
	
	Once we found an approximate descent direction $w_{k,j}$, the steplength $\alpha_{k,j}$ is computed as the one dimensional minimizer of $m_k(x_{k,j}+\alpha w_{k,j})$ on the intersection of the line $\alpha \ge 0$ with the feasible domain. Since $Aw_{k,j}=0$, we only need to make sure that the bounds and trust region constraints are satisfied. The procedure we employ is similar to the one implemented in LANCELOT~\cite[][section 3.2.3]{conn-etal:1992}.
	A simple computation shows that the unconstrained minimizer of the model along the direction $w_{k,j}$ would be
	\begin{equation}
		\alpha_*^{(k,j)} = \left\{\begin{aligned}
			&-\dfrac{\inner{\nabla m_k(x_{k,j})}{w_{k,j}}}{\inner{w_{k,j}}{H_kw_{k,j}}} & &\text{if } \inner{w_{k,j}}{H_kw_{k,j}} > 0 \\
			&\infty & &\text{otherwise}
		\end{aligned} \right.
	\end{equation}
	We still need to account for the maximum step allowed by the constraints~\eqref{subeq:minor_subpb_bounds} on the free variables:
	\begin{equation}
		\alpha_i^{(k,j)} = \left\{\begin{aligned}
			&l_i^{(k,j)}/[w_{k,j}]_i & &\text{if } [w_{k,j}]_i < 0 \\
			&u_i^{(k,j)}/[w_{k,j}]_i & &\text{if } [w_{k,j}]_i > 0 \\
			&\infty & &\text{otherwise}
		\end{aligned} \right.
	\end{equation}
	for $i \in \calF(x_{k,j})$.
	The steplength is then
	\begin{equation}\label{eq:minor_iterate_steplength}
		\alpha_{k,j} = \min \left\{ \alpha_*^{(k,j)}, \min_{i \in \calF(x_{k,j})} \alpha_i^{(k,j)} \right\}.
	\end{equation}
	Another, and maybe more efficient approach, would be to compute the steplength by a projected search~\cite{moretoraldo:1991,linmore:1999a}. This allows to add more than one constraint to the active set but would also require to compute the projection of the gradient direction~\eqref{eq:projected_gradient_path} on the feasible set $\Omega$ at every new trial value of the steplength. When $\Omega$ only contains bound constraints, the projection is trivial and cheap to compute. The linear equality case is more costly but can still be handled efficiently by a \textit{normal equations} or \textit{augmented system} approach~\cite{gould-etal:2001}. When $\Omega$ is of the form~\eqref{eq:linear_constraints}, the projection is less trivial and requires to solve the associated minimum-distance quadratic program with a dedicated solver for QP, which we currently prefer to avoid.
	
	%		$\min_{v \in \Omega} \ \|v +tg_k-x_k \|$ 
	
	We stop the minor-iterations procedure when the reduced gradient associated to the current active set is small enough. More formally, assume we performed the $j+1$ minor minimizations and let $\tilde{N}_{(k,j)}$ form an orthonormal basis of the matrix representing the linear equality constraints and the active bounds in $\calA(x_{k,j})$. We stop whenever the following inequality is satisfied:
	\begin{equation}\label{eq:reduced_gradient_stop_condition}
		\left\Vert \tilde{N}_{(k,j)}^T \nabla m_k(x_{k,j+1})\right\Vert \le \kappa_3 \left\Vert \tilde{N}_{(k,j)}^T \nabla m_k(x_k)\right\Vert.
	\end{equation}
	This inequality estimates if there is relative progress that can be made in the tangent subspace spanned by the free variables. Since the basis represented by $\tilde{N}_{(k,j)}$ is orthonormal, reduced vectors of the form $\tilde{N}_{(k,j)}^Tv$ have the same norm as their projection $\tilde{P}_{(k,j)}v$ on this nullspace, where $\tilde{P}_{(k,j)}$ is defined as in~\eqref{eq:minor_subpb_projector}. Thus, the two sides of the inequality~\eqref{eq:reduced_gradient_stop_condition} can be evaluated relatively efficiently. 
	
	We have described our algorithm with respect to formulation~\eqref{eq:model_cnls} with equality constraints but we also accepts problems with nonlinear inequality constraints of the form $g(x) \ge 0$. We transform the latter into equality constraints by adding non-negative slack variables, which gives the new constraints
	\begin{equation}
		g(x) - u = 0,\quad u \ge 0.
	\end{equation}.
	The lower and upper bounds associated to these slack variables are thus $0$ and $\infty$ respectively. Of course, a similar treatment can be applied to transform potential linear inequality constraints into equalities.
	The Augmented Lagrangian is now 
	\[\Phi_A(x,u,\lambda,\mu) = \varphi(x,u) = \dfrac{1}{2} \|r(x)\|^2 + \inner{\lambda}{\begin{pmatrix}
			c(x) \\ g(x) - u
	\end{pmatrix}} + \dfrac{\mu}{2} \left\| \begin{matrix}
		c(x) \\ g(x) - u
	\end{matrix}\right\|^2\] 
	When slack variables are present, the step can be complemented by an additional \textit{magical} step that is guaranteed to further reduce the AL function. This procedure, described in~\cite{conn-etal:1999} and also used in~\cite{arreckx-etal:2016}, consists into a special update of the slack variables that exploits the structure of the AL. Let $(x_k,u_k)$ be the current iterate and $\left((\bar{s}_k)_x,(\bar{s}_k)_u\right)$ the first step computed by algorithm\todo{add an algorithmic description of the step computation}. We note the associated trial point 
	\[\begin{pmatrix}
		\bar{x}_k \\ \bar{u}_k
	\end{pmatrix}=
	\begin{pmatrix} x_k \\ u_k \end{pmatrix} + \begin{pmatrix} (\bar{s}_k)_x \\ (\bar{s}_k)_u \end{pmatrix}.\]
	Since $u \mapsto \Phi_A(x,u,\lambda,\mu)$ 
	is quadratic and convex, we can further minimize $\Phi_A$ by solving 
	\begin{equation}\label{eq:al_min_wrt_slack} 
		\begin{aligned}
			\min_{u} \quad& \varphi(\bar{x}_k,u) \\
			\text{s.t.}  \quad & u \ge 0. 
		\end{aligned}	
	\end{equation}
	The solution, noted $\hat{u}_k$, is explicit and its components are given by
	\begin{equation}\label{eq:magical_step}
		\left(\hat{u}_k\right)_i = \max\left(0, \dfrac{\lambda_i}{\mu} + g_i(\bar{x}_k)\right).
	\end{equation}
	The trial step for the current iteration is thus
	\begin{equation}\label{eq:magical_trial_step}
		s_k = \begin{pmatrix}
			(s_k)_x \\ (s_k)_u
		\end{pmatrix} =
		\begin{pmatrix}
			(\bar{s}_k)_x \\ \hat{u}_k-\bar{u}_k.
		\end{pmatrix}
	\end{equation}
	Using the latter step is tantamount to directly setting the slack variables values to~\eqref{eq:magical_step}, as we do not change the step relative to the $x$ variables. This also implies that it does not require additional functions evaluations, since one only needs $r(\bar{x}_k)$ and $g(\bar{x}_k)$ to compute the actual reduction $\varphi\left(x_k+(s_k)_x,u_k+(s_k)_u\right)$. However, the predicted reduction needs to be changed to reflect the effect of the complementary step. Since we did not use the model to compute the second step, it is not relevant to evaluate the model reduction at $s_k$. A suitable choice is to define the new predicted reduction as the sum of the predicted reduction obtained by the first step with the actual reduction obtained by the second step, i.e.
	\begin{equation}\label{eq:pred_magical_step}
		q_k(s_k) + \varphi\left(x_k+(s_k)_x,u_k+(s_k)_u\right) - \varphi\left(x_k+(\bar{s}_k)_x,u_k+(\bar{s}_k)_u\right).
	\end{equation} 
	During our numerical experiments, we have observed significant robustness improvements of the algorithm on problems with inequality constraints.
	
	\subsection{About the Hessian approximation}\label{subsec:hessian_approx}
	
	We now discuss how the Hessian of the AL is iteratively updated when we define the quadratic model of iteration $k$ in algorithm~\ref{algo:trinner_iteration}. To set up the context and notations of this paragraph, we wish to approximate the true Hessian
	\[\nabla_{xx}^2 \varphi(x_k) = J_k^TJ_k + \mu C_k^TC_k + S_k,\]  
	by a symmetric matrix $H_k$.
	We remind that the need for an approximation mainly comes form the fact that evaluating the second order terms in $S_k$ requires too much time and storage to be done in practice, especially for problems with a large number of variables and residuals.
	
	
	The first approximation we can think of, and the simplest one, is obtained after merely linearizing the residuals and constraints in expression~\eqref{eq:al}, which gives
	\begin{equation}\label{eq:hessian_gn_approx}
		H_k = J_k^TJ_k + \mu C_k^TC_k.
	\end{equation}
	We will call it the Gauss-Newton (GN) approximation, in reference to its counterpart in the unconstrained case. On the one hand, this approximation is very convenient and cheap as it involves already available first-order derivatives, since they are required to evaluate the gradient. Also, when the Jacobians are full rank, the resulting matrix is positive-definite which guarantees the convexity of subproblems of the form~\eqref{eq:inner_itr_subpb}. On the other hand, it is known to be less efficient on problems with non zero residuals at the solution. This downside is amplified when we are to approximate the Hessian of the Lagrangian, or the AL in our case. Indeed, setting $S_k$ to the zero matrix not only neglects the contribution of the residuals to the curvature of the model, but is also neglects the contribution of the Lagrange multipliers, for which there are no reasons to equal zero.
	
	We thus need to take into account the full Hessian to form an approximation. Looking at the literature on this subject, one can observe that there is a variety of approaches focusing on the unconstrained case, as it is a major challenge in improving the efficiency of algorithms for problems with non zero residuals at the solution. Nevertheless, relevant parallels can be drawn with the AL situation, or the constrained case in general, since these studies explore techniques to deal with second order terms. Because the first-order terms are readily available and provide curvature information, only the second-order components need to be approximated. Therefore, we look for an approximation of the form 
	\begin{equation}\label{eq:hessian_full_approx}
		H_k = B^{GN}_k + B_k.
	\end{equation}
	where $B^{GN}_k$ is the right hand side of~\eqref{eq:hessian_gn_approx} and  $B_k$ is a symmetric approximation of $S_k$. The simplest choice, apart from setting $S_k=0$, is to approximate $S_k$ by a scalar multiple of the identity matrix $\sigma_k I$ where $\sigma_k$ is an iteration dependent regularization parameter. This approach, known as the Levenberg-Marquardt~\cite{levenberg:1944,marquardt:1963} (LM) method, is more robust than the GN method and performs well in practice, although on paper, it can be slowly convergent on large residuals problems. This technique have also been used in algorithms for nonlinear least-squares with equality constraints. Indeed, the authors in~\cite{bergou-etal:2021} use it to approximate the Hessian of the Lagrangian, whereas in~\cite{orbansiquiera:2020}, the authors add primal and dual regularization terms to the objective function in order to derive a regularized KKT system of equations.  
	
	The third class of methods, and the one we will use, consists to start with an initial approximation $S_0$ and update it iteratively after by a formula derived from a secant equation. Standard quasi-Newton methods employ DFP, BFGS or SR1 formulas~\cite[][Chapter 6]{nocedalwright:2006}. Since this exploits the structure of the Hessian, we will talk about structured quasi-Newton (SQN) methods.
	If $B_k$ is the current approximation of $S_k$, in order to compute the approximation $B_{k+1}$ of $S_{k+1}$, we require that a secant equation of the form
	\begin{equation}\label{eq:structured_secant_equation}
		B_{k+1}s_k = y_k,
	\end{equation}
	is satisfied. In~\eqref{eq:structured_secant_equation}, $s_k$ is the iteration step and the right hand side $y_k$ is defined after available quantities relative to the current iteration. Then, as for standard quasi-Newton methods, one can impose $B_{k+1}$ to be close to $B_k$ for a chosen matrix norm, which yields the DFP and BFGS formulas, or require a rank-one equation to be satisfied, for the SR1 formula. All these approaches, with different secant equations, have been studied and specialized to least-squares problems, with additional features to deal with sizing strategies~\cite{betts:1976,biggs:1977,dennisetal:1981,dennis-etal:1989, huschens1994,lucksan-etal:2019}. We also mention the SQN methods proposed in~\cite{yabetakahashi:1991, zhouchen:2010}, and the references therein, where the matrix $S_k$ is approximated in factorized form by imposing a secant equation on a lower triangular matrix $L_k$ such that $S_k \approx L_k^TL_k$. 
	
	Structured approximations of the AL Hessian have been studied for general objective functions~\cite{tapia:1988} but our approach is closer to the one employed in~\cite{li-etal:2002}. In the latter, the authors base their approximation on a secant equation derived from a heuristic initially introduced in the unconstrained case~\cite{biggs:1977} that they adapted to approximate the Hessian of the Lagrangian and use it in a SQP algorithm for constrained nonlinear least-squares. This strategy is also at the heart of the SQN method from the popular package for unconstrained nonlinear least-squares NL2SOL~\cite{dennisetal:1981,dennis-etal:1989}. The idea is the following. If we were to approximate each matrix term of the sum~\eqref{eq:al_hessian_2nd_terms}, we would have
	\begin{equation}\label{eq:sum_hessian_approximations}
		B_{k+1} = \sum_{i=1}^{n_r}  r_i(x_{k+1}) B^{r_i}_{k+1} + \sum_{i=1}^{n_c} \bar{\lambda}_i(x_{k+1},\lambda,\mu) B^{c_i}_{k+1},
	\end{equation}
	with $B^{r_i}_{k+1} \approx \nabla^2r_i(x_{k+1})$ and $B^{c_i}_{k+1} \approx  \nabla^2 c_i(x_{k+1})$. To get an accurate approximation, given a step $s_k$, it is reasonable to require
	\begin{equation}\label{eq:components_secant_equations}
		B^{r_i}_{k+1}s_k = \nabla r_i(x_{k+1}) - \nabla r_i(x_k) \qquad \text{and} \qquad B^{c_i}_{k+1}s_k = \nabla c_i(x_{k+1}) - \nabla c_i(x_k),
	\end{equation}
	i.e. that each Hessian maps the change in the variables to the change in the gradients. Noticing that, for each $i$, $\nabla r_i(x_{k+1}) - \nabla r_i(x_k)$, resp. $\nabla c_i(c_{k+1}) - \nabla c_i(x_k)$, is the $i$-th row of $\left(J_{k+1}-J_k\right)^T$, resp. $\left(C_{k+1}-C_k\right)^T$, summing over the residuals and constraints indices all the terms of~\eqref{eq:components_secant_equations} gives, by~\eqref{eq:sum_hessian_approximations}, the structured secant equation
	\begin{equation}\label{eq:structured_sr1_secant_eq}
		B_{k+1}s_k = \left(J_{k+1}-J_k\right)^Tr_{k+1} + \left(C_{k+1}-C_k\right)^T\bar{\lambda}_{k+1}.
	\end{equation}
	To follow the conventional notations of quasi-Newton methods, we will note $y_k:= g_{k+1}-g_k$ and denote the right hand side of~\eqref{eq:structured_secant_equation} by $y^A_k$ to insist on its link with the AL formulation.
	
	We choose to update our approximated Hessian with the SR1 formula 
	\begin{equation}\label{eq:structured_sr1_update}
		B_{k+1} = B_k + \dfrac{(y^A_k-B_ks_k)(y^A_k-B_ks_k)^T}{(y^A_ks_k-B_ks_k)^Ts_k},
	\end{equation}
	if $(y^A_k-S_ks_k)^Ts_k \neq 0$. When the denominator in~\eqref{eq:structured_sr1_update} is zero, we simply set $B_{k+1}=B_k$. To avoid numerical errors, we apply the update when
	\begin{equation}\label{eq:structured_sr1_safeguard}
		\left|\inner{y^A_k-S_ks_k}{s_k}\right| \ge \kappa_{sr1}\|s_k\|\|y^A_k-S_ks_k\|,
	\end{equation}
	for $\kappa_{sr1} \in (0,1)$. Inequality~\eqref{eq:structured_sr1_safeguard} is one of the most commons safeguards used in SR1 methods. 
	
	The choice of the SR1 method is motivated by its robustness in the least-squares context, as the exhaustive benchmarks in~\cite{lucksan-etal:2019} show, and its tendency to better approximate the true Hessian with each iteration~\cite{conn-etal:1991a}. The approximation could thus be indefinite, which could be considered as a weakness compared to BFGS of DFP updates, that are guaranteed to be positive definite as long as it is the case for the initial approximation $B_0$. However, as it is highlighted in algorithm~\ref{algo:projected_cg_method}, the use of the conjugate gradients method in a trust region framework handles, and even exploits, the potential non-convexity of the subproblems. Moreover, this update does not require a curvature condition $\inner{s_k}{y_k} > 0$ to be satisfied. In other works on the constrained case, SQN methods are used to approximate the projected Hessian of the Lagrangian \cite{tjoabiegler:1991}, or of a merit function~\cite{amiribartels:1989}, in the null space of the active constraints. The BFGS update is then preferred because this matrix is, under standard assumptions, positive semidefinite, according to the second-order necessary conditions.
	
	We end our description of the Hessian approximation by discussing about hybrid updates, a feature that we do not implement but that is commonly used in SQN methods for nonlinear least-squares algorithms, either in the unconstrained~\cite{dennisetal:1981,albaalifletcher:1985,fletcherxu:1987} or constrained~\cite{tjoabiegler:1991,li-etal:2002} case. The idea is to test at every iteration if the problem has small or large residuals at the solution. In the latter case, a structured update is used to increase the accuracy of the approximated Hessian whereas in the former, the GN approximation is employed. Note that the update, such as~\eqref{eq:structured_sr1_update}, is still computed at every iteration to continue accumulate curvature information. We have tested a strategy inspired from~\cite{fletcherxu:1987} adapted to the constrained case, that computes the relative reduction
	\begin{equation}\label{eq:relative_reduction_al}
		\zeta_k = \dfrac{\varphi(x_{k})-\varphi(x_{k+1})}{\varphi(x_{k})},
	\end{equation}
	and updates the approximated Hessian based on the rule
	\begin{equation}\label{eq:hybrid_update_strategy}
		H_{k+1} = \left\{\begin{aligned}
			&B^{GN}_{k+1} & &\text{if } \zeta_k \le \kappa_{hyb} \\
			&B^{GN}_{k+1} + B_{k+1} & & \text{otherwise}, 
		\end{aligned}\right.
	\end{equation}
	where $\kappa_{hyb}$ is a parameter in $(0,1)$. Update~\eqref{eq:hybrid_update_strategy} is used with $\kappa_{hyb}=0.1$ in~\cite{tjoabiegler:1991} where the AL plays the role of a merit function. We observed that the algorithm does less outer and inner iterations without using an hybrid switching rule. We suspect that a rule base on the ratio~\eqref{eq:relative_reduction_al} is not suited for the AL Hessian, as there are second-order terms that can not legitimately be neglected even for small residuals problems and close to a feasible point.
	
	\subsection{Summary and implementation details}\label{sec:implementation_details}
	
	We end our description of algorithm TRALCNLLS by summarizing the relations between outer, inner and minor iterates and the default values for the different constants exposed in this section.
	\begin{itemize}
		\item The outer iterates $x_K$ are the main iterates of the algorithm and are approximate minimizers of the AL
		\item Each outer iterate is formed after a sequence of inner iterates $(x_k)_k$, linked by $x_{k+1}=x_k+s_k$ where $s_k$ is an approximate solution of the QP~\eqref{eq:qsubpb}
		\item Each inner iterate is formed after a sequence of $M$ minor iterates $x_{k,j}$ linked by $x_{k,j+1}=x_{k,j}+\alpha_{k,j}w_{k,j}$ where
		\begin{itemize}
			\item $w_{k,j}$ is a descent direction obtained by applying the projected conjugate gradient algorithm~\ref{algo:projected_cg_method}
			\item $\alpha_{k,j}$ is a steplength given by~\eqref{eq:minor_iterate_steplength}
		\end{itemize}
	\end{itemize} 
	Our intention with the work presented in this paper was to conceive an algorithm able to handle directly linear constraints of the form~\eqref{eq:linear_constraints} but we also accept problems where linear constraints are only bounds and then
	\[\Omega = \left\{x \in \RR^n \ |\ l \le x \le u\right\}.\]
	The framework we have presented remains valid for this formulation. The only practical difference is in the computation of projections. In the bound constrained  case, the projection of a vector $x$ on the set $\calB$ has components
	\begin{equation}\label{eq:projection_bounds}
		\left(\proj{\Omega}{x}\right)_i = 
		\left\{ \begin{aligned}
			& l_i & &\text{if } x_i < l_i \\
			& x_i & &\text{if } x_i \in [l_i,u_i] \\
			& u_i & &\text{if } x_i > u_i
		\end{aligned} \right.
	\end{equation}
	One could argue that, since computing~\eqref{eq:projection_bounds} is cheaper than solving the normal equations~\eqref{eq:proj_normal_eq_auxiliary_syst}, we could make use of projected searches~\cite{moretoraldo:1991} as it is done in the solver TRON~\cite{linmore:1999a}. Indeed, this method have interesting convergence properties and could improve the efficiency of the Cauchy step computation or the steplength. We preferred, however, not to include it, because with a feasible region of the form~\eqref{eq:linear_constraints}, projected searches require to compute projections very often, which could negatively impact the performance. Nevertheless, those are likely to be investigated for future updates of the bounds constrained version. The other practical difference with the polyhedral case is that we use the infinite norm of the projected gradient, i.e.
	\[\pi(x_K) = \left\| x_K - \proj{\Omega}{x_K-\Phi_A(x_K,\lambda_K,\mu_K)}\right\|_\infty.\]
	The default values for tolerances and constants of algorithm~\ref{algo:basic_al_trm} are
	\[ \mu_0 = 10,\ \kappa_\omega = \beta_\omega = \eta = \omega = 1,\ \kappa_\eta = 0.1,\ \beta_\eta = 0.9,\ \tau = 100,\  \omega^*=\eta^* = 10^{-7}.\]
	Constants relative to the inner minimization process of algorithm~\ref{algo:trinner_iteration} are set to
	\[ \kappa_1=10^{-2},\ \kappa_2 = \kappa_3 = 0.1,\ \gamma_c = 10.\]
	We now discuss aspects relative to the trust region handling. The initial radius value for algorithm~\ref{algo:trinner_iteration} is set to
	\begin{equation}\label{eq:initial_radius}
		\Delta_0 = 0.1\| g_0\|_\infty.
	\end{equation}
	The mechanism to update the trust region given in~\eqref{eq:tr_basic_update} still leaves important flexibility. We choose to follow a standard strategy similar to the one exposed in~\cite[][Chapter 17]{conn-etal:2000}. We also added a refinement to handle the case where the ratio $\rho_k$ is negative, which can happen when there is very poor agreement between the function and the model. In such cases, we reduce more severely the radius by taking
	\[\Delta_{k+1} = \gamma_1 \Delta_k.\]
	The complete update rule for the trust region radius is then
	\begin{equation}\label{eq:tr_update}
		\Delta_{k+1} = \left\{\begin{aligned}
			& \max\left(\alpha_2 \|s_k\|_\infty,\Delta_k\right) & &\text{if } \rho_k \ge \eta_2 \\
			& \Delta_k &  &\text{if } \rho_k \in [\eta_1,\eta_2) \\
			& \alpha_1\Delta_k & &\text{if } \rho_k \in [0,\eta_1) \\
			& \min\left(\alpha_1 \|s_k\|_\infty,\gamma_1\Delta_k\right) & &\text{if } \rho_k < 0,
		\end{aligned}\right.
	\end{equation}
	with constant values
	\[\alpha_1 = 0.25,\ \alpha_2 = 2.5,\ \eta_1 = 0.25,\ \eta_2 = 0.75,\ \gamma_1 = 0.0625.\]
	We have also implemented two safeguards to prevent the inner minimization algorithm from stalling. This can occur when the trust region radius is so small that no relative progress can be made, or when two consecutive iterates are indistinguishable from  each, up to a relative tolerance. For the former, we stop algorithm~\ref{algo:trinner_iteration} when 
	\begin{equation}\label{eq:very_small_radius}
		\Delta_k \le \epsilon_{rad} \|x\|_\infty,
	\end{equation}
	for some $\epsilon_{rad} > 0$. For the second condition, the algorithm is stopped when
	\begin{equation}
		\left|(s_k)_i\right| < \epsilon_{step} \left|(x_k)_i\right|,
	\end{equation}
	for all $i=1,\ldots,n$ such that $(x_k)_i \neq 0$. In our implementation, we have set
	\[ \epsilon_{rad}=\epsilon_{step}=\sqrt{\epsilon_{dbl}},\]
	where $\epsilon_{dbl}$ is the relative double machine precision. During our numerical experiments, we have tested several values, but these ones best reflected the numerical intuition that a radius or step were ``too'' small in norm.
	
	\section{Convergence analysis}\label{sec:global_convergence}
	
	In this section, we prove global convergence of algorithm~\ref{algo:basic_al_trm} to a first-order critical point. Since our algorithm follows classic theory of Augmented Lagrangian methods, so does our proof of convergence. We start by prooving global convergence of the inner minimization algorithm~\ref{algo:trinner_iteration}. This ensures that step 1 of algorithm~\ref{algo:basic_al_trm} always succeeds and that outer iterates are well defined. 
	
	\subsection{Global convergence of the inner minimization}
	
	We start by proving the global convergence of the inner minimization process of algorithm~\ref{algo:trinner_iteration}. This ensures that the inner minimization of algorithm~\ref{algo:basic_al_trm} always succeeds. Because of the similarities between our algorithms, the proof given in this paper follows the structure of the one outlined in~\cite{conn-etal:1988a}. Most of the work consists into formulating and adapting intermediate results to the polyhedral case. 
	
	We first make the standard assumption
	\begin{assumption}\label{assumption:inner_iterates_compact}
		The set $\calX = \left\{x \ | \ \varphi(x) \le \varphi(x_0)\right\} \cap \Omega$ is non empty and compact.
	\end{assumption}
	Combined with the fact that the objective function $\varphi$ is twice continuously differentiable, this ensures that there exists a solution to problem~\eqref{eq:inner_itr_subpb}.
	
	We now introduce notations, some of them being taken from previous sections. 	
	
	We remind that the quadratic model is of the form
	\[q_k(s) = \dfrac{1}{2} \inner{s}{H_ks} + \inner{g_k}{s},\]
	where $g_k = \nabla \varphi(x_k)$ and $H_k$ is an approximation of the Hessian based on the structured SR1 formula from~\ref{subsec:hessian_approx}. We formulate two assumptions relative to those approximations. The norm used is the induced norm on matrices, i.e. $\|M\| := \sup_{\|x\|=1} \|Mx\|$ for a given matrix $M$.
	\begin{assumption}\label{assumption:model_hessian}
		Defining, for every iteration index $k$, the scalars $b_k$ by 
		\[b_k = 1+\max_{0 \le i \le k} \ \left\| H_i\right\|,\]
		we require that the series $\sum_k \frac{1}{b_k}$ diverges to $\infty$.
	\end{assumption}
	The second assumption and states that the norm of the approximating Hessians should not increase too fast compared with the speed of convergence of the function values.
	\begin{assumption}\label{assumption:hessian_norm_compared_convergence_speed}
		\[\lim\limits_{k\to \infty} b_k (\varphi_{k+1}-\varphi_k) = 0.\]
	\end{assumption}
	
	The projected gradient path is defined as
	\[s_k(t)=\proj{\Omega}{x_k-tg_k}-x_k \text{ for } t\ge 0.\]
	The reduction of the model along the projected gradient path may thus be defined as the piecewise quadratic function
	\[\psi(t) = q_k(s_k(t)),\]
	and we denote by $t_k^C$ the first local minimum of $\psi$ subject to the trust region constraint 
	\begin{equation}
		\|s_k(t)\|_\infty \le \Delta_k.
	\end{equation}
	The associated Cauchy step is 
	\begin{equation}\label{eq:cauchy_step}
		s_k^C = s_k(t_k^C).
	\end{equation}
	Because of the choice of the $\ell_\infty$ norm, computing $s_k(t)$ within the trust region corresponds to project the direction $x_k-tg_k$ onto
	\begin{equation}\label{eq:proj_grad_feasible_set}
		\left\{d \in \RR^n \ | \ Ad=0,\ l_k \le d \le u_k\right\},
	\end{equation}
	with $(l_k)_i = \max\left(-\Delta_k,l_i-(x_k)_i\right)$ and $(u_k)_i = \min\left(\Delta_k,u_i-(x_k)_i\right)$ for all $i=1,\ldots,n$.
	
	We assume that the total step $s_k$ produces a fraction of the reduction achieved by the Cauchy point:
	\begin{equation}\label{eq:step_drecrease_wrt_cauchy}
		q_k(s_k) \le \kappa_{fcd} \ q_k(s_k^C),
	\end{equation}
	for $\kappa_{fcd} \in (0,1]$. 
	
	We detail the behavior of the polygonal line $s_k(t)$. At first, if no bounds are active at $x_k$, projecting on the set~\eqref{eq:proj_grad_feasible_set} for $t$ close to $0$ is equivalent to projecting onto the null space of $A$. As $t$ increases, the direction might hit several bounds. Since the set of active bounds can only be increased, we have that
	\begin{equation}\label{eq:nested_active_sets}
		I(x_k+s_k(t)) \subseteq I(x_k+s_k(t^\prime)) \quad \text{for all}\ 0 < t \le t^\prime.
	\end{equation}
	Let 
	\[0=t_0 < t_1 < \ldots < t_p,\]
	be the successive values of $t$ at which the projected step $s_k(t)$ hits a bound, also called breakpoints. Hitting a bound not only affects the corresponding components, that are now fixed, but it also affects the other components, as the steepest direction must now be projected on a subspace of the form 
	\[\left\{d \in \RR^n \ | \ Ad=0,\ d_i=0\ \text{for some}\ i\right\}\]
	This motivates to adapt the notion of tangent space at a point on the projected gradient path:
	\begin{equation}\label{eq:tangent_space}
		T(t) := \left\{ d \in \RR^n \ | \ Ad = 0,\ d_i=0\ \text{for all}\ i\in I(x_k+s_k(t))\right\},
	\end{equation}
	for $t\ge0$. This enables us to give a recursive expression of $s_k(t)$ on each interval $[t_i,t_{i+1})$, with $0 \leq i \le p$, as:
	\begin{equation}\label{eq:projected_gradient_path_recursion}
		s_k(t) = (t-t_i) \proj{T(t_i)}{-g_k} + s_k(t_i).
	\end{equation}
	We also define the reduced gradient on the projected gradient path:
	\begin{equation}
		z_k(t) := \proj{T(t)}{g_k},
	\end{equation}
	and state a first lemma on how the tangent spaces and the reduced gradients at two different positions compare to each other.
	\begin{lemma}\label{lemma:non_increasing_reduced_gradient_norm}
		For all $0 < t < t^\prime$, we have that 
		\begin{equation}\label{eq:lemma_tangent_spaces_inclusion}
			T(t) \supseteq T(t^\prime),
		\end{equation}
		and
		\begin{equation}\label{eq:lemma_reduced_gradient_norm}
			\|z_k(t)\| \ge \|z_k(t^\prime)\|.
		\end{equation}
	\end{lemma}
	\begin{proof}
		The first statement follows from the inclusion~\eqref{eq:nested_active_sets}. Inequality~\eqref{eq:lemma_reduced_gradient_norm} then results from the fact that projecting the same vector on a smaller linear subspace reduces the norm of its projection. 
	\end{proof}
	When referring to the tangent space and the reducted gradient at a given breakpoint $t_i$, we will make use of the shorthand notation $T_i := T(x_k+s_k(t_i))$ and $z_i:=z_k(t_i)$. Notice that because the active set is fixed on each interval $[t_i,t_{i+1})$, so is the tangent space and hence, the reduced gradient is constant. Also, we can deduce from lemma~\ref{lemma:non_increasing_reduced_gradient_norm} that the tangent spaces associated to each breakpoint form a finite sequence of nested linear subspaces
	\[T_0 \supseteq T_1 \supseteq \ldots \supseteq T_p.\]
	We can now expand equation~\eqref{eq:projected_gradient_path_recursion}:
	\begin{equation}\label{eq:projected_gradient_path_full_expr}
		s_k(t) = -(t-t_i)z_i - \sum_{j=0}^{i-1}(t_{j+1}-t_j)z_j,
	\end{equation}
	which shows than on each interval $(t_i,t_{i+1})$, $s_k(t)$ is differentiable w.r.t. $t$ and that
	\begin{equation}\label{eq:projected_gradient_path_derivative}
		s_k^\prime(t) = -z_k(t) = -z_i,
	\end{equation}
	for $t \in (t_i,t_{i+1})$.
	
	Our proof follows the structure of proof of global convergence given in~\cite{conn-etal:1988a} because of the similarity between our algorithm and the one described in~\cite{conn-etal:1988b}, used in the inner minimization phase of LANCELOT~\cite{conn-etal:1992} for the bound constrained case. Most of the work consists into giving an adapted formulation for the intermediate results involving the structure of the linear constraints. 
	We start by establishing an inequality on the decrease of the objective function after taking step $s_k$. This will involve the norm of the projected gradient, i.e.:
	\begin{equation}\label{eq:crit_norm_projected_grad}
		h_k := \left\|s_k(1)\right\|.
	\end{equation}
	
	\begin{lemma}\label{lemma:majoration_reduced_gradient_norm}
		If assumptions \ref{assumption:functions_C2}, \ref{assumption:full_rank_A}, \ref{assumption:inner_iterates_compact} hold and that $h_k>0$, then 
		\[\|z_k(t_k^{(1)})\| \ge \dfrac{h_k}{2},\]
		where $\kappa_{ubg}$ is the constant defined by \[\kappa_{ubg} := \max\left(1, \max_{x \in \calX} \|\nabla \varphi(x)\|\right),\] 
		and $t_k^{(1)}=\frac{h_k}{2\kappa_{ubg}}$.
	\end{lemma}
	
	\begin{proof} 
		First note that the constant $\kappa_{ubg}$ is well defined because $\varphi$ is continuously differentiable on $\calX$, the latter being compact by assumption~\ref{assumption:inner_iterates_compact}.
		
		By non-expansivity of the projection mapping onto the convex set $\Omega$, one has, for any $t\ge 0$:
		\begin{equation}
			\begin{split}
				\left\| s_k\left(t\right) \right\| & = \left\| \proj{\Omega}{x_k-tg_k}-x_k\right\| \\
				& = \left\| \proj{\Omega}{x_k-tg_k}-\proj{\Omega}{x_k}\right\| \\
				& \le \left\| x_k-tg_k-x_k\right\|\\
				& \le t\|g_k\|.
			\end{split}
		\end{equation}
		Choosing $t=t_k^{(1)}$ and because $\|g_k\|\le \kappa_{ubg}$ by definition of $\kappa_{ubg}$, we get
		\begin{equation}\label{eq:norm_proj_grad_t1}
			\| s_k(t_k^{(1)})\| \le \dfrac{h_k}{2}.
		\end{equation}
		Now, defined $t_k^{(2)}$ as the smallest $t\ge 0$ such that
		\begin{equation}\label{eq:def_t2}
			\|s_k(t_k^{(2)})\| = h_k.
		\end{equation}
		By~\eqref{eq:norm_proj_grad_t1}, we have
		\begin{equation}\label{eq:t1_leq_t2}
			0 < t_k^{(1)} < t_k^{(2)} \le 1.
		\end{equation}
		On each interval $(t_i,t_{i+1})$, the left, resp. right, derivative of $s_k(t)$ at $t_i$, resp. $t_{i+1}$, are well defined and equal $z_i$. We can thus rewrite~\eqref{eq:projected_gradient_path_full_expr} as
		\begin{equation}
			s_k(t) = \int_{t_i}^{t} s_k^\prime(t)dt + \sum_{j=0}^{i-1} \int_{t_j}^{t_{j+1}} s_k^\prime(t)dt,
		\end{equation} 
		which we simplify by
		\begin{equation}\label{eq:projected_gradient_path_integral_form}
			s_k(t) = -\int_{0}^{t} z_k(t)dt,
		\end{equation}
		using~\eqref{eq:projected_gradient_path_derivative} and keeping in mind that it is a sum of integrals defined on each segment $[t_i,t_{i+1}]$. 
		Now let $i_1$, resp. $i_2$ be the breakpoint index such that $t_k^{(1)} \in [t_{i_1},t_{i_1+1})$, resp. $t_k^{(2)} \in [t_{i_2},t_{i_2+1})$. Then by~\eqref{eq:projected_gradient_path_integral_form}:
		\begin{equation}
			s_k(t_k^{(2)}) - s_k(t_k^{(1)}) = -\int_{t_k^{(1)}}^{t_k^{(2)}} z_k(t)dt, 
		\end{equation}
		which leads to
		\begin{equation}\label{eq:ineq_dist_proj_grad_t1t2}
			\begin{split}
				\|s_k(t_k^{(2)}) - s_k(t_k^{(1)})\| & \le \int_{t_k^{(1)}}^{t_k^{(2)}} \|z_k(t)\|dt \\
				& \le \int_{t_k^{(1)}}^{t_k^{(2)}} \|z_k(t_k^{(1)})\|dt \\
				& \le (t_k^{(2)}-t_k^{(1)}) \|z_k(t_k^{(1)})\|,
			\end{split}
		\end{equation}
		where we have used~\eqref{eq:lemma_reduced_gradient_norm} to bound the norm of the reduced gradient on $[t_k^{(1)},t_k^{(2)}]$.
		Combined with~\eqref{eq:t1_leq_t2} and~\eqref{eq:def_t2}, we get
		\begin{equation}
			\begin{split}
				\|z_k(t_k^{(1)})\| & \ge (t_k^{(2)}-t_k^{(1)}) \|z_k(t_k^{(1)})\| \\
				& \ge \|s_k(t_k^{(2)}) - s_k(t_k^{(1)})\| \\
				& \ge \|s_k(t_k^{(2)})\| - \|s_k(t_k^{(1)})\| \\
				& \ge \dfrac{h_k}{2},
			\end{split}
		\end{equation}
		which is the desired inequality.
	\end{proof}
	
	The next lemma gives an upper bound on the quadratic model $\psi(t)$ in an interval of interest.
	
	\begin{lemma}\label{lemma:bound_model_proj_grad_path}
		If assumptions~\ref{assumption:functions_C2}, \ref{assumption:full_rank_A}, \ref{assumption:inner_iterates_compact} hold and that for some $t_k^{(3)}>0 $, one has
		\[\alpha_k = \|z_k(t_k^{(3)})\| > 0,\]
		then, if $T$ is the set of points in $[0,t_k^{(3)}]$ at which the piecewise quadratic $\psi$ is differentiable, 
		\begin{equation}\label{eq:lemma_ineq_model_derivative_t3}
			\psi^\prime(t) \le -\alpha_k^2 + t_k^{(3)}\kappa_{ubg}^2\|H_k\|,
		\end{equation}
		for all $t\in T$.
		
		Furthermore, 
		\begin{equation}\label{eq:lemma_ineq_model_derivative_t4}
			\psi^\prime(t) \le -\dfrac{1}{2}\alpha_k^2 ,
		\end{equation}
		for all $t\in T \cap [0,t_k^{(4)}]$ and 
		\begin{equation}\label{eq:lemma_ineq_model_t4}
			\psi(t) \le  - \dfrac{\alpha_k^2}{2}t,
		\end{equation}
		for all $t\in  [0,t_k^{(4)}]$ where 
		\begin{equation}\label{eq:t4_def}
			t_k^{(4)} = \min \left(t_k^{(3)}, \dfrac{\alpha_k^2}{2\kappa_{ubg}^2(\|H_k\|+1)}\right).
		\end{equation}
	\end{lemma}
	
	\begin{proof}
		For $t \in T$, let $i$ be the breakpoint index such that $t\in(t_i,t_{i+1})$. On the latter interval, $\psi$ is differentiable and we have, by expression~\eqref{eq:projected_gradient_path_full_expr}:
		\begin{equation}\label{eq:model_proj_grad_path_derivative}
			\begin{split}
				\psi^\prime(t) & = \inner{g_k}{s_k^\prime(t)} + \inner{s_k(t)}{H_ks_k^\prime(t)} \\
				& = -\inner{g_k}{z_i} - \inner{s_k(t)}{H_kz_i}.
			\end{split}
		\end{equation}
		Because $z_i$ is, by definition, the orthogonal projection of the vector $g_k$ on a linear subspace:
		\begin{equation}\label{eq:ineq_derivative_model_first_order}
			\begin{split}
				\inner{g_k}{z_i} & = \inner{z_i}{z_i} \\
				& \ge \|z_k(t_k^{(3)})\|^2 = \alpha_k^2,
			\end{split}
		\end{equation}
		where the last inequality follows from the monotonicity of the reduced gradient norm on $[0,\infty)$. 
		
		We now look at the quadratic terms. First, by Cauchy-Schwarz inequality:
		\begin{equation}
			\left|\inner{s_k(t)}{H_kz_i}\right| \le \|s_k(t)\| \|H_kz_i\|.
		\end{equation}
		Then, applying the triangle inequality to expression~\eqref{eq:projected_gradient_path_full_expr}, we obtain
		\begin{equation}\label{eq:norm_proj_grad_step_ineq}
			\begin{split}
				\|s_k(t)\| & \le (t-t_i) \|z_i\| + \sum_{j=0}^{i-1} (t_{j+1}-t_j)\|z_j\| \\
				& \le (t-t_i) \|g_k\| + \sum_{j=0}^{i-1} (t_{j+1}-t_j)\|g_k\| \\
				& \le t\|g_k\| \le t_k^{(3)}\kappa_{ubg},
			\end{split}
		\end{equation}
		where we have used the facts that for all breakpoints indices $j$, $\|z_i\| \le \|g_k\| \le \kappa_{ubg}$ and that the scalar $t$ is taken in $T$. For the remaining terms:
		\begin{equation}
			\|H_kz_i\| \le \|H_k\| \|z_i\| \le \kappa_{ubg}\|H_k\|.
		\end{equation}
		Combining the latter inequality with~\eqref{eq:norm_proj_grad_step_ineq}, we get the following bound for the quadratic terms:
		\begin{equation}\label{eq:ineq_derivative_model_second_order}
			\left|\inner{s_k(t)}{H_kz_i}\right| \le t_k^{(3)} \kappa_{ubg}^2 \|H_k\|.
		\end{equation}
		Hence, using~\eqref{eq:ineq_derivative_model_first_order} and~\eqref{eq:ineq_derivative_model_second_order}:
		\begin{equation}
			\psi^\prime(t) \le -\alpha_k^2 + t_k^{(3)} \kappa_{ubg}^2 \|H_k\|,
		\end{equation}
		for all $t \in T$, which proves~\eqref{eq:lemma_ineq_model_derivative_t3}.
		Now, considering $t_k^{(4)}$ as defined by~\eqref{eq:t4_def}, since $t_k^{(4)} \le t_k^{(3)}$, we get that $\|z_k(t_k^{(4)})\| \ge \alpha_k > 0$. The above reasoning based on $t_k^{(4)}$ thus yields
		\begin{equation}
			\psi^\prime(t) \le -\alpha_k^2 + t_k^{(4)} \kappa_{ubg}^2 \|H_k\| \le -\dfrac{\alpha_k^2}{2},
		\end{equation}
		for $t\in T$, $t\le t_k^{(4)}$. It follows that, for all $t\in [0,t_k^{(4)}]$:
		\begin{equation}
			\psi(t) \le -\dfrac{\alpha_k^2}{2}t,
		\end{equation}
		which completes the proof.
	\end{proof}
	
	The next lemma bounds the decrease guaranteed by the step.
	\begin{lemma}\label{lemma:step_guaranteed_decrease}
		If assumptions~\ref{assumption:functions_C2}, \ref{assumption:full_rank_A}, \ref{assumption:inner_iterates_compact}, \ref{assumption:model_hessian} hold and that $h_k > 0$, then
		\begin{equation}\label{eq:bound_step_decrease}
			q_k(s_k) \le -\kappa_{mdc} h_k^2 \min\left(\dfrac{h_k^2}{b_k},\Delta_k\right),
		\end{equation}
		where 
		\begin{equation}
			\kappa_{mdc} = \dfrac{\kappa_{fcd}}{64\kappa_{ubg}^2}.
		\end{equation}
		Furthermore, if iteration $k$ is successful, then
		\begin{equation}\label{eq:bound_successful_step_decrease}
			\varphi(x_k) - \varphi(x_k+s_k) \ge \kappa_{sdc} h_k^2 \min\left(\dfrac{h_k^2}{b_k},\Delta_k\right),
		\end{equation}
		with $\kappa_{sdc} = \eta_1 \kappa_{mdc}$.
	\end{lemma} 
	\begin{proof}
		We first observe that if we use $t_1^{(k)}$ as $t_k^{(3)}$ in the proof of lemma~\ref{lemma:bound_model_proj_grad_path} and apply lemma~\ref{lemma:majoration_reduced_gradient_norm}, we get 
		\begin{equation}\label{eq:model_bound_t1}
			q_k(t) \le -\dfrac{h_k^2}{0} t,
		\end{equation}
		for $t \in [0,t_k^{(5)}]$ with \[t_k^{(5)} := \min\left(t_k^{(1)},\dfrac{h_k^2}{8\kappa_{ubg}^2 (\|H_k\|+1)}\right) = \dfrac{h_k^2}{8\kappa_{ubg}^2 (\|H_k\|+1)}.\]
		First, assume that $\|s_k(t_k^{(5)})\|_\infty \le \Delta_k.$ Then \footnote{TODO: might have to justify this ``then"}, by~\eqref{eq:step_drecrease_wrt_cauchy}:
		\begin{equation}\label{eq:model_decrease_cauchy_in_tr}
			q_k(s_k) \le -\kappa_{fcd} \frac{h_k^2}{8} t_k^{(5)}.
		\end{equation}
		Now, assume that $\|s_k(t_k^{(5)})\|_\infty > \Delta_k$. The latter implies that $\|s_k(t_k^C)\|_\infty = \Delta_k$ and from
		\begin{equation}
			\left\|s_k\left(\frac{\Delta_k}{\kappa_{ubg}}\right)\right\|_\infty \le 	\left\|s_k\left(\frac{\Delta_k}{\kappa_{ubg}}\right)\right\| \le \frac{\Delta_k}{\kappa_{ubg}} \|g_k\| \le \Delta_k,
		\end{equation}
		we can deduce that 
		\begin{equation}
			t_k^C \ge \frac{\Delta_k}{\kappa_{ubg}}.
		\end{equation}
		Therefore, using~\eqref{eq:model_bound_t1} with $t=t_k^C$ and~\eqref{eq:step_drecrease_wrt_cauchy} implies
		\begin{equation}\label{eq:model_decrease_cauchy_at_tr}
			q_k(s_k) \le -\kappa_{fcd} \frac{h_k^2}{8\kappa_{ubg}} \Delta_k \le -\kappa_{fcd} \frac{h_k^2}{64c^2_2} \Delta_k,
		\end{equation} 
		because $\kappa_{ubg} \ge 1.$
		The inequality~\eqref{eq:bound_step_decrease} results from gathering~\eqref{eq:model_decrease_cauchy_in_tr},~\eqref{eq:model_decrease_cauchy_at_tr} and the definition of scalar $b_k$. 
		
		Finally, if the step is successful, we get inequality~\eqref{eq:bound_successful_step_decrease} by using~\eqref{eq:bound_step_decrease} and the step acceptance condition $\rho_k > \eta_1$ from algorithm~\ref{algo:trinner_iteration}. 
	\end{proof}
	
	Once we have established the guaranteed decrease inequality, the rest of the proof does not involve the polyhedral structure of the constraints and we can fall back into the standard convergence theory of trust region methods. We state the main convergence theorem, whose proof and intermediate developments can be found in~\cite{conn-etal:1988a}.
	\begin{theorem}[Theorem 11 from~\cite{conn-etal:1988a}]
		If assumptions~\ref{assumption:functions_C2}, \ref{assumption:full_rank_A}, \ref{assumption:inner_iterates_compact}, \ref{assumption:model_hessian}, \ref{assumption:hessian_norm_compared_convergence_speed} hold, then
		\[\lim\limits_{k\to \infty} h_k = 0.\]
	\end{theorem}
	
	\subsection{Global convergence of the algorithm}
	
	The content of this section follows the developments exposed in~\cite{conn-etal:1996b}. In this paper, the authors prove global convergence of Augmented Lagrangian methods for problems where the non-penalized constraints are linear inequalities, which fits to our context. Indeed, it is trivial that linear constraints of problem~\eqref{eq:model_cnls} can be written $\bar{A}x \ge \bar{b}$ with \[ \bar{A} = \begin{pmatrix}
		A \\ -A \\ I \\ -I
	\end{pmatrix} 
	\text{ and } \bar{b} = \begin{pmatrix} b \\ -b \\ l \\ -u \end{pmatrix}.\]
	
	
	Let $(x_k)_k$ be an infinite sequence of outer iterates generated by algorithm~\ref{algo:basic_al_trm}. The use of subscript $k$ si preferred for clarity. We make the following assumption.
	\begin{assumption}\label{assumption:iterates_domain_bounded}
		The iterates lie within a closed bounded domain of $\Real^n$.
	\end{assumption}
	
	The last assumption mixes a constraint qualification of the nonlinear constraints and a condition for the simultaneous feasibility of both nonlinear and linear constraints.
	Before formulating it, we introduce some notations used throughout the rest of this section. 
	
	Let $\calK \subseteq \NN$ such that the sub-sequence $(x_k)_{k\in \calK}$ converges to a limit point $x^*$. Then $Z_*$ denotes a null space matrix of the linear constraints active at $x^*$, i.e. all the equalities and the active bounds. 
	\begin{assumption}\label{assumption:cq_null_space_jacobian}
		The rank of matrix $C(x^*)Z_*$ is no smaller than $n_c$ at any limit point $x^*$ of the sequence $(x_k)_k$.
	\end{assumption}
	Assumption~\ref{assumption:cq_null_space_jacobian} ensures that the dimension of the null space of the active linear constraints is large enough to achieve feasibility of the nonlinear constraints and that their gradients are linearly independent within that space. With this assumption, the least-squares Lagrange multipliers estimates
	\begin{equation}\label{eq:least_squares_multipliers}
		\lambda^{LS}(x) = \left[C(x)Z_*\right]^\dagger Z_*^T\nabla f(x),
	\end{equation}
	are well defined at $x=x^*$ with $\left[C(x)Z_*\right]^\dagger$ denoting the pseudo-inverse~\cite{generalizedinverses} of $C(x)Z_*$.
	
	In the following theorem, written in the spirit of \cite[Lemma 4.4 , Theorem 4.6]{conn-etal:1996b} we state our global convergence result.
	
	\begin{theorem}\label{theo:global_convergence_tralcnls}
		Assume that assumptions~\ref{assumption:functions_C2}~and~\ref{assumption:feasible_linear_cons} hold. Let $(x_k)_{k\in \calK}$ be an infinite sub-sequence of iterates produced by algorithm~\ref{algo:basic_al_trm} converging to a limit point $x^*$ for which assumptions~\ref{assumption:iterates_domain_bounded} and~\ref{assumption:cq_null_space_jacobian} hold and let $\lambda^*=\lambda^{LS}(x^*)$ be its associate least-squares multipliers. Then $c(x^*)=0$ and $x^*$ is a first-order critical point of problem~\eqref{eq:model_cnls} with corresponding multipliers $\lambda^*$. Moreover, the sequence $\left(\bar{\lambda}(x_k,\lambda_k,\mu_k)\right)_{k \in \calK}$ converges to $\lambda^*$.   
	\end{theorem}
	
	%%%%%%%%%%%%%%%% APPENDIX 
	\clearpage
	\section*{Appendix}
	
	\appendix
	
	\section{Block Cholesky factorization of the augmented matrix}\label{appendix:chol_aug_matrix}
	
	In this appendix, we show how to construct the Cholesky decomposition of the matrix $\tilde{A}\tilde{A}^T$, where $\tilde{A}$ has been introduced at~\eqref{eq:active_constraints_matrix}. We remind that, considering a set of index of active bounds $\calA =  \left\{i_1,\ldots, i_p\right\}$, $p < n-m$, we have
	\[\tilde{A} = \begin{bmatrix}
		A \\ Z
	\end{bmatrix} \in \RR^{(m+p)\times n},\]
	where $Z \in \RR^{p\times n}$ the matrix whose row $k$ is the row $i_k$ of the $n\times n$ identity matrix.
	We assume that we already know a $m\times m$ lower triangular matrix $L$ such that $AA^T=LL^T$. Following the reasoning in~\cite[][section 4.2.9]{golubvanloan:2013}, we will show how, at the cost of extra computations, we can recover the Cholesky factor $\tilde{L}$ using the block structure of $\tilde{A}\tilde{A}^T$ and the factor $L$. The definition of $\tilde{A}$ naturally leads to the block pattern
	\[\tilde{A}\tilde{A}^T = \begin{bmatrix}
		AA^T & AZ^T \\ ZA^T & ZZ^T.
	\end{bmatrix}\]
	Simple computations first show that 
	\[ZZ^T = I_p,\quad AZ^T = [A_{i_1},\ldots,A_{i_p}].\]
	The latter, written $A_{|\calA}$, is the restriction of A to the columns corresponding to the indices in $\calA$. Let $\tilde{L}$ be $(m+p)\times(m+p)$ triangular such that $\tilde{A}\tilde{A}^T=\tilde{L}\tilde{L}^T$. We apply the same block structure to $\tilde{L}$, i.e.
	\[\tilde{L} = \begin{bmatrix}
		\tilde{L}_{11} & 0 \\ \tilde{L}_{21} & \tilde{L}_{22},
	\end{bmatrix},\]
	with 
	\begin{itemize}
		\item $\tilde{L}_{11} \ m\times m$ lower triangular
		\item $\tilde{L}_{21} \ p\times m$
		\item $\tilde{L}_{22} \ p \times p$ lower triangular
	\end{itemize}
	Verifying $\tilde{A}\tilde{A}^T= \tilde{L}\tilde{L}^T$ implies the matrix equality
	\begin{equation}\label{eq:block_equalities_chol_fact}
		\begin{bmatrix}
			AA^T &  A_{|\calA} \\  A_{|\calA}^T & I_p.
		\end{bmatrix}
		=
		\begin{bmatrix}
			\tilde{L}_{11}\tilde{L}_{11}^T & \tilde{L}_{11}\tilde{L}_{21}^T \\ 
			\tilde{L}_{21}\tilde{L}_{11}^T & \tilde{L}_{21}\tilde{L}_{21}^T + \tilde{L}_{22}\tilde{L}_{22}^T
		\end{bmatrix}.
	\end{equation}
	By comparison of the blocks in~\eqref{eq:block_equalities_chol_fact}, it follows that
	\begin{equation*}
		\begin{aligned}
			AA^T &= \tilde{L}_{11}\tilde{L}_{11}^T \\
			A_{|\calA} &= \tilde{L}_{11}\tilde{L}_{21}^T \\
			I_p &= \tilde{L}_{21}\tilde{L}_{21}^T + \tilde{L}_{22}\tilde{L}_{22}^T.
		\end{aligned}
	\end{equation*}
	Therefore, we can form $\tilde{L}$ by first setting $\tilde{L}_{11}=L$, then solve $m$ lower triangular systems to compute $\tilde{L}_{21}$ and finally compute the Cholesky factor of $I_p-\tilde{L}_{21}\tilde{L}_{21}^T$ to get $\tilde{L}_{22}$.
	
	%%%%%%%%%%%%%%%%%% BIBLIOGRAPHY
	\clearpage
	\bibliographystyle{plainnat}
	\bibliography{refs}
\end{document}



